{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGYwt_UjIrqp"
   },
   "source": [
    "# Instance Segmentation\n",
    "\n",
    "Source\n",
    "<a href=\"https://colab.research.google.com/drive/11MqMCyF_V7Rkw6b9CCShGfNTP59OJ905?usp=sharing\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cCk6uTQrdUUn"
   },
   "source": [
    "If you are running the tutorial files on the colab platform or a new virtual environment, please run the following code first to configure the runtime environment.\n",
    "```python\n",
    "!pip install -U openmim\n",
    "!mim install \"mmengine>=0.7.0\"\n",
    "!mim install \"mmcv>=2.0.0rc4\"\n",
    "\n",
    "# Install mmdetection\n",
    "!rm -rf mmdetection\n",
    "!git clone https://github.com/open-mmlab/mmdetection.git\n",
    "%cd mmdetection\n",
    "\n",
    "!pip install -e .\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6hD0mmMixT0p",
    "outputId": "221dad3c-5ef8-4094-e07e-289f333f7bb9"
   },
   "outputs": [],
   "source": [
    "# Check Pytorch installation\n",
    "import torch, torchvision\n",
    "print(\"torch version:\",torch.__version__, \"cuda:\",torch.cuda.is_available())\n",
    "\n",
    "# Check MMDetection installation\n",
    "import mmdet\n",
    "print(\"mmdetection:\",mmdet.__version__)\n",
    "\n",
    "# Check mmcv installation\n",
    "import mmcv\n",
    "print(\"mmcv:\",mmcv.__version__)\n",
    "\n",
    "# Check mmengine installation\n",
    "import mmengine\n",
    "print(\"mmengine:\",mmengine.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gi9zw03oM4CH"
   },
   "source": [
    "## Perform Inference with An MMDetection Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWI-nX5yRYYQ",
    "outputId": "fd91e337-27cb-492c-a948-98adcbcfca27"
   },
   "outputs": [],
   "source": [
    "# !mim download mmdet --config mask-rcnn_swin-s-p4-w7_fpn_amp-ms-crop-3x_coco --dest ./checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8M5KUnX7Np3h",
    "outputId": "71de79c0-9f7e-4cae-f810-5c0a20fe9be8"
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "import mmengine\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "from mmdet.utils import register_all_modules\n",
    "# Choose to use a config and initialize the detector\n",
    "\n",
    "config_file = './checkpoints/mask-rcnn_swin-s-p4-w7_fpn_amp-ms-crop-3x_coco.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint_file = './checkpoints/mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco_20210903_104808-b92c91f1.pth'\n",
    "\n",
    "# register all modules in mmdet into the registries\n",
    "register_all_modules()\n",
    "\n",
    "# build the model from a config file and a checkpoint file\n",
    "model = init_detector(config_file, checkpoint_file, device='cuda:0') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4pFVhKeQRYYS"
   },
   "source": [
    "### Let's plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YinmJV1dRYYT",
    "outputId": "e6c9059f-55b3-481b-edef-b21befcbcf2e"
   },
   "outputs": [],
   "source": [
    "from mmdet.registry import VISUALIZERS\n",
    "# init visualizer(run the block only once in jupyter notebook)\n",
    "visualizer = VISUALIZERS.build(model.cfg.visualizer)\n",
    "# the dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer.dataset_meta = model.dataset_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7GrWIJywLV-V"
   },
   "source": [
    "## Train a Detector on A Customized Dataset\n",
    "\n",
    "To train a new detector, there are usually three things to do:\n",
    "1. Support a new dataset\n",
    "2. Modify the config\n",
    "3. Train a new detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaYkWbxORwZq",
    "outputId": "02ad1ff6-f138-49af-b733-1d23c51557f5"
   },
   "outputs": [],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Path to load the COCO annotation file\n",
    "annotation_file = './roboflow_datasets/xmm_om_artefacts_512-3-COCO/train/_annotations.coco.json'\n",
    "\n",
    "# Initialise the COCO object\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "# Get all category tags and corresponding category IDs\n",
    "categories = coco.loadCats(coco.getCatIds())\n",
    "category_id_to_name = {cat['id']: cat['name'] for cat in categories}\n",
    "\n",
    "# Print all category IDs and corresponding category names\n",
    "for category_id, category_name in category_id_to_name.items():\n",
    "    print(f\"Category ID: {category_id}, Category Name: {category_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PwqJOpBe-bMj"
   },
   "source": [
    "### Modify the config\n",
    "\n",
    "In the next step, we need to modify the config for the training.\n",
    "To accelerate the process, we finetune a detector using a pre-trained detector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hamZrlnH-YDD"
   },
   "outputs": [],
   "source": [
    "from mmengine import Config\n",
    "cfg = Config.fromfile('./checkpoints/mask-rcnn_swin-s-p4-w7_fpn_amp-ms-crop-3x_coco.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HntziLGq-92Z"
   },
   "source": [
    "Given a config that trains a Mask R-CNN on COCO dataset, we need to modify some values to use it for training on the balloon dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pUbwD8uV0PR8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmengine.runner import set_random_seed\n",
    "\n",
    "# Modify dataset classes and color\n",
    "cfg.metainfo = {\n",
    "    'classes': ('artefacts', 'central-ring', 'smoke-ring','star-loop'),\n",
    "    'palette': [\n",
    "        (220, 20, 60), (220, 20, 60), (220, 20, 60), (220, 20, 60)\n",
    "    ]\n",
    "}\n",
    "\n",
    "cfg.data_root = './roboflow_datasets/xmm_om_artefacts_512-3-COCO/'\n",
    "\n",
    "cfg.train_dataloader.dataset.ann_file = 'train/_annotations.coco.json'\n",
    "cfg.train_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.train_dataloader.dataset.data_prefix.img = 'train/'\n",
    "cfg.train_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.val_dataloader.dataset.ann_file = 'valid/_annotations.coco.json'\n",
    "cfg.val_dataloader.dataset.data_root = cfg.data_root\n",
    "cfg.val_dataloader.dataset.data_prefix.img = 'valid/'\n",
    "cfg.val_dataloader.dataset.metainfo = cfg.metainfo\n",
    "\n",
    "cfg.test_dataloader = cfg.val_dataloader\n",
    "\n",
    "# Modify metric config\n",
    "cfg.val_evaluator.ann_file = cfg.data_root+'/'+'valid/_annotations.coco.json'\n",
    "cfg.test_evaluator = cfg.val_evaluator\n",
    "\n",
    "# Modify num classes of the model in box head and mask head\n",
    "cfg.model.roi_head.bbox_head.num_classes = 4\n",
    "cfg.model.roi_head.mask_head.num_classes = 4\n",
    "\n",
    "# We can still the pre-trained Mask RCNN model to obtain a higher performance\n",
    "cfg.load_from = './checkpoints/mask_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco_20210903_104808-b92c91f1.pth'\n",
    "# Set up working dir to save files and logs.\n",
    "cfg.work_dir = './mmdet_work_dir'\n",
    "\n",
    "# We can set the evaluation interval to reduce the evaluation times\n",
    "cfg.train_cfg.val_interval = 3\n",
    "# We can set the checkpoint saving interval to reduce the storage cost\n",
    "cfg.default_hooks.checkpoint.interval = 3\n",
    "cfg.visualizer.vis_backends = [\n",
    "        dict(type='LocalVisBackend'),\n",
    "        dict(type='WandbVisBackend'),\n",
    "    ]\n",
    "# The original learning rate (LR) is set for 8-GPU training.\n",
    "# We divide it by 8 since we only use one GPU.\n",
    "# cfg.optim_wrapper.optimizer.lr = 0.02 / 8\n",
    "cfg.default_hooks.logger.interval = 10\n",
    "\n",
    "# Set seed thus the results are more reproducible\n",
    "# cfg.seed = 0\n",
    "set_random_seed(0, deterministic=False)\n",
    "\n",
    "# We can also use tensorboard to log the training process\n",
    "# cfg.visualizer.vis_backends.append({\"type\":'TensorboardVisBackend'}) # this must be commented if it is already appended\n",
    "\n",
    "#------------------------------------------------------\n",
    "config=f'./checkpoints/mask-rcnn_swin-s-p4-w7_fpn_amp-ms-crop-3x_coco.py'\n",
    "with open(config, 'w') as f:\n",
    "    f.write(cfg.pretty_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.visualizer.vis_backends = cfg.visualizer.vis_backends[:1]\n",
    "cfg.visualizer.vis_backends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg.visualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "111W_oZV_3wa"
   },
   "source": [
    "### Train a new detector\n",
    "\n",
    "Finally, lets initialize the dataset and detector, then train a new detector!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If using simply 'python', it will run from the env where the jupyter was launched from. We need to specify the current env interpreter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JiqDnPdAMGyg",
    "outputId": "0de25679-3541-488e-eceb-5b5400f92745",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! /opt/conda/envs/openmmlab_3/bin/python ../mmdetection/tools/train.py {config}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_vYQF5K2NqqI"
   },
   "source": [
    "### Understand the log\n",
    "From the log, we can have a basic understanding on the training process and know how well the detector is trained.\n",
    "\n",
    "First, since the dataset we are using is small, we loaded a Mask R-CNN model and finetune it for detection. Because the original Mask R-CNN is trained on COCO dataset that contains 80 classes but KITTI Tiny dataset only have 3 classes. Therefore, the last FC layers of the pre-trained Mask R-CNN for classification and regression have different weight shape and are not used. The pre-trained weights of mask prediction layer `mask_head.conv_logits` also does not matches the current model and is not used due to similar reason.\n",
    "\n",
    "Third, after training, the detector is evaluated by the default COCO-style evaluation. The results show that the detector achieves 79.6 bbox AP and 81.5 mask AP on the val dataset, not bad!\n",
    "\n",
    " We can also check the tensorboard to see the curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbLNlJR-RYYd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pip install tensorboard  -i https://mirrors.ustc.edu.cn/pypi/web/simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfQ-yspZLuuI"
   },
   "source": [
    "## Test the Trained Detector\n",
    "\n",
    "After finetuning the detector, let's visualize the prediction results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_MuZurfGLq0p",
    "outputId": "4b25759c-8e22-405e-a061-3abc44e38043",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import mmcv\n",
    "from mmdet.apis import init_detector, inference_detector\n",
    "img = mmcv.imread('../XMM_OM_dataset/zscaled_512_stretched/S0105460201_M.png',channel_order='rgb')\n",
    "checkpoint_file = './mmdet_work_dir/epoch_36.pth'\n",
    "model = init_detector(cfg, checkpoint_file, device='cpu')\n",
    "new_result = inference_detector(model, img)\n",
    "print(new_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "7SSTauCURYYe",
    "outputId": "3becb5ea-cb4e-44f6-d93d-c10194a2263b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from mmengine.visualization import Visualizer\n",
    "# get built visualizer\n",
    "visualizer_now = Visualizer.get_current_instance()\n",
    "# the dataset_meta is loaded from the checkpoint and\n",
    "# then pass to the model in init_detector\n",
    "visualizer_now.dataset_meta = model.dataset_meta\n",
    "# show the results\n",
    "visualizer_now.add_datasample(\n",
    "    'new_result',\n",
    "    img,\n",
    "    data_sample=new_result,\n",
    "    draw_gt=False,\n",
    "    wait_time=0,\n",
    "    out_file=None,\n",
    "    pred_score_thr=0.5\n",
    ")\n",
    "visualizer_now.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "def show_masks(masks, ax, random_color=False):\n",
    "    for mask in masks:\n",
    "        if random_color:\n",
    "            color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "        else:\n",
    "                color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "        h, w = mask.shape[-2:]\n",
    "        mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "        ax.imshow(mask_image)\n",
    "\n",
    "plt.imshow(img)\n",
    "show_masks(new_result.pred_instances.masks.cpu().numpy(), plt.gca())\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rzruCwFgPXm"
   },
   "source": [
    "## What to Do Next?\n",
    "\n",
    "So far, we have learnt how to test and train Mask R-CNN. To further explore the segmentation task, you could do several other things as shown below:\n",
    "\n",
    "- Try cascade methods, e.g., [Cascade Mask R-CNN](https://github.com/open-mmlab/mmdetection/tree/master/configs/cascade_rcnn) and [HTC](https://github.com/open-mmlab/mmdetection/tree/master/configs/htc) in [MMDetection model zoo](https://github.com/open-mmlab/mmdetection/blob/master/docs/en/model_zoo.md). They are powerful detectors that are ranked high in many benchmarks, e.g., COCO dataset.\n",
    "- Try single-stage methods, e.g., [K-Net](https://github.com/ZwwWayne/K-Net) and [Dense-RepPoints](https://github.com/justimyhxu/Dense-RepPoints). These two algorithms are based on MMDetection. Box-free instance segmentation is a new trend in the instance segmentation community.\n",
    "- Try semantic segmentation. Semantic segmentation is also a popular task with wide applications. You can explore [MMSegmentation](https://github.com/open-mmlab/mmsegmentation/); we also provide a [colab tutorial](https://github.com/open-mmlab/mmsegmentation/blob/master/demo/MMSegmentation_Tutorial.ipynb) for semantic segmentation using MMSegmentation.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "openmmlab_3_k",
   "language": "python",
   "name": "openmmlab_3_k"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "8868640c17582ff5a3e06365ba2fb344ce697cf42d4745ae8b85a9738303c037"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
