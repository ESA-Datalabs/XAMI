{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db94333e",
   "metadata": {},
   "source": [
    "useful doc: https://photutils.readthedocs.io/en/stable/background.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# math symbols\n",
    "med = r\"$\\tilde{x}$\"\n",
    "biw_loc = r\"$\\zeta_{\\text{biloc}}$\"\n",
    "mean_symbol = r'$\\bar{x}$' \n",
    "std_symbol = r'$\\sigma$'    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2a6837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import astronomy_utils\n",
    "reload(astronomy_utils)\n",
    "from astronomy_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf26d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/S0202730101_B.png' # and S0412991401_U\n",
    "usual_input_file = '/workspace/raid/XMM_OM_code/spring.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf14b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "\n",
    "usual_image = cv2.imread(usual_input_file, cv2.IMREAD_COLOR)\n",
    "usual_data = cv2.cvtColor(usual_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "image = cv2.imread(input_file, cv2.IMREAD_COLOR)\n",
    "data = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "data_2D = np.dot(data[..., :3], [0.21, 0.72, 0.07]) \n",
    "usual_data_2D = np.dot(usual_data[..., :3], [0.21, 0.72, 0.07]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec6e8de-3953-42c4-9349-bcfc4251daf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((usual_data - 123)/58)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3bd166-b97d-49eb-b4fd-c04fa0855bce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/workspace/raid/OM_DeepLearning/XMM_OM_code_git/xmm_om_images_v4-contrast-512-1/train/_annotations.coco.json') as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ff64e9-203d-4443-940d-e84df3529f3f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images = dataset['images']\n",
    "\n",
    "img_keys = []\n",
    "for i in range(len(images)):\n",
    "    img_keys.append(\"_\".join(images[i]['file_name'].split('_')[:2])+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d2133-009d-4a91-b3b9-140c498af9d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc5a29c",
   "metadata": {},
   "source": [
    "**AsinhStretch and LogStretch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79caba40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.visualization import AsinhStretch, LogStretch\n",
    "\n",
    "# mask negative pixels\n",
    "data = 255 - data\n",
    "normalized_data = data/255.0\n",
    "negative_mask = (data>0).astype(int)\n",
    "non_negative_data = normalized_data * negative_mask\n",
    "\n",
    "asinh_factor = 0.1\n",
    "log_factor = 100.0\n",
    "# Apply AsinhStretch\n",
    "data_asinh_stretched = image_stretch(non_negative_data, 'asinh', asinh_factor)\n",
    "\n",
    "# Apply LogStretch\n",
    "data_log_stretched = image_stretch(non_negative_data, 'log', log_factor)\n",
    "\n",
    "# Gamma correction\n",
    "gamma = 2\n",
    "gamma_corrected = np.uint8((non_negative_data ** gamma)*255.0)\n",
    "\n",
    "def plot_image_statistics(data, mask_on_negative_area=True):\n",
    "\n",
    "        if mask_on_negative_area:\n",
    "            data = data[data>0]\n",
    "            \n",
    "        data_median = np.median(data[data>0]).round(3)\n",
    "        data_biw = biweight_location(data[data>0]).round(3)\n",
    "        data_mean = np.mean(data[data>0]).round(3)\n",
    "        data_std = np.std(data[data>0]).round(3)\n",
    "\n",
    "        return f\" x͂ = {data_median}, ζ_biw = {data_biw}\\n x̄ = {data_mean}, σ = {data_std}\"\n",
    "\n",
    "plt.figure(figsize=(15, 10)) \n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "plt.imshow(data,cmap='gray')\n",
    "plt.title(f'Image {input_file.split(\"/\")[-1]}\\n {plot_image_statistics(non_negative_data, mask_on_negative_area=True)}')\n",
    "\n",
    "plt.subplot(2,4,2)\n",
    "plt.imshow(data_asinh_stretched)\n",
    "plt.title(f'Asinh Stretch factor = {asinh_factor}\\n {plot_image_statistics(data_asinh_stretched, mask_on_negative_area=True)}')\n",
    "\n",
    "plt.subplot(2,4,3)\n",
    "plt.imshow(data_log_stretched)\n",
    "plt.title(f'Log Stretch factor = {log_factor}\\n {plot_image_statistics(data_log_stretched, mask_on_negative_area=True)}')\n",
    "\n",
    "plt.subplot(2,4,4)\n",
    "plt.imshow(gamma_corrected)\n",
    "plt.title(f'Gamma correction (γ = {gamma})')\n",
    "\n",
    "plt.subplot(2,4,5)\n",
    "plt.hist(np.dot(normalized_data[..., :3], [0.21, 0.72, 0.07]).flatten(), bins=100)\n",
    "plt.title(\"Normalized 2D Image histogram\")\n",
    "\n",
    "plt.subplot(2,4,6)\n",
    "plt.hist(data_asinh_stretched.flatten(), bins=100)  \n",
    "plt.title(\"Asinh Stretched Image histogram\")\n",
    "\n",
    "plt.subplot(2,4,7)\n",
    "plt.hist(data_log_stretched.flatten(), bins=100)  \n",
    "plt.title(\"Log Stretched Image histogram\")\n",
    "\n",
    "plt.subplot(2,4,8)\n",
    "plt.hist(gamma_corrected.flatten(), bins=100)  \n",
    "plt.title(\"Gamma correction Image histogram\")\n",
    "\n",
    "plt.savefig('./plots/asinh_log_stretches.png', dpi=500)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69f9bb0-3df4-4740-8c91-30c79b272983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import glob\n",
    "\n",
    "# directory = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/zscaled_512_rescaled_SAM_stats/'\n",
    "# files = glob.glob(f'{directory}/*')\n",
    "# for file in files:\n",
    "#     os.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262851c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.visualization import AsinhStretch, LogStretch, simple_norm\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import astronomy_utils\n",
    "reload(astronomy_utils)\n",
    "from astronomy_utils import *\n",
    "\n",
    "def normalize_image_to_0_255(image):\n",
    "    # Find the min and max pixel values\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "\n",
    "    # Normalize the image to 0-1\n",
    "    normalized_image = (image - min_val) / (max_val - min_val)\n",
    "\n",
    "    # Scale to 0-255 and convert to uint8\n",
    "    final_image = (normalized_image * 255).astype(np.uint8)\n",
    "\n",
    "    return final_image\n",
    "    \n",
    "dir_in = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/'\n",
    "output_dir = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/zscaled_512_rescaled_SAM_stats/'\n",
    "import math\n",
    "k=0\n",
    "\n",
    "for img_key in img_keys: # in os.listdir(dir_in):\n",
    "    if '.png' in img_key and 'clahe' not in img_key and k<30:\n",
    "        k+=1\n",
    "        \n",
    "        image_in = cv2.imread(dir_in+img_key)\n",
    "        data_in = cv2.cvtColor(image_in, cv2.COLOR_BGR2RGB)\n",
    "        data_in = 255-data_in\n",
    "        use_stretch, use_clahe = False, False\n",
    "        \n",
    "        # print('mean:', np.mean(data_in[data_in>0])/255.0, 'std:', np.std(data_in[data_in>0])/255.0)\n",
    "        \n",
    "        # if use_clahe:\n",
    "        #     data_in = clahe_algo_image(dir_in+file_, clipLimit=4.0, tileGridSize=(5,5))\n",
    "        #     print(np.mean(data_in)/255.0, np.std(data_in)/255.0)\n",
    "\n",
    "        if True:\n",
    "            normalized_data = (data_in - np.max(0, np.min(data_in)))/(np.max(data_in) - np.max(0, np.min(data_in))) # normalized up to 0 values, not less\n",
    "            negative_mask = (data_in>0).astype(int)\n",
    "            non_negative_data = normalized_data * negative_mask\n",
    "\n",
    "            data_mean = np.mean(non_negative_data[non_negative_data>0])\n",
    "            \n",
    "            if data_mean < 0.3:\n",
    "                asinh_factor = 0.1\n",
    "                factor = f'Asinh (factor = {asinh_factor})'\n",
    "                stretched_data = image_stretch(non_negative_data, 'asinh', asinh_factor)\n",
    "            elif data_mean > 0.5:\n",
    "                gamma = 2\n",
    "                factor = f'Gamma correction (γ = {gamma})'\n",
    "                stretched_data = np.uint8((non_negative_data ** gamma) * 255.0)\n",
    "                stretched_data = stretched_data/255.0\n",
    "            else:\n",
    "                asinh_factor = 0.5\n",
    "                factor = f'Asinh (factor = {asinh_factor})'\n",
    "                stretched_data = image_stretch(non_negative_data, 'asinh', asinh_factor)\n",
    "\n",
    "        scaled_image_to_SAM_statistics = rescale_flattened_image(stretched_data, negative_mask, 0.45, 0.225)\n",
    "        \n",
    "        output_file = output_dir+img_key\n",
    "        cv2.imwrite(output_file, stretched_data*255.0)\n",
    "        fig, axs = plt.subplots(1, 6, figsize=(20, 8)) \n",
    "\n",
    "        axs[0].imshow(data_in)\n",
    "        axs[0].set_title(f'{img_key}\\nx̄ = {np.mean(non_negative_data[non_negative_data<255]).round(3)}, σ = {np.std(non_negative_data[non_negative_data<255]).round(3)}', fontsize=12)\n",
    "\n",
    "        axs[1].imshow(stretched_data)\n",
    "        axs[1].set_title(f'Stretched image\\n{factor}\\nx̄ = {np.mean(stretched_data[stretched_data<255]).round(3)}, σ = {np.std(stretched_data[stretched_data<255]).round(3)}', fontsize=12)\n",
    "        \n",
    "        axs[2].imshow(scaled_image_to_SAM_statistics)\n",
    "        axs[2].set_title(f'Rescaled image (after stretch)\\nx̄ = {np.mean(scaled_image_to_SAM_statistics[scaled_image_to_SAM_statistics<255]).round(3)}, σ = {np.std(scaled_image_to_SAM_statistics[scaled_image_to_SAM_statistics<255]).round(3)}', fontsize=12)\n",
    "\n",
    "        axs[3].imshow((stretched_data - np.mean(stretched_data[stretched_data<255]))/np.std(stretched_data[stretched_data<255]))\n",
    "        axs[3].set_title(f'Norm image (after stretch)', fontsize=12)\n",
    "\n",
    "        axs[4].imshow((data_in - np.mean(data_in))/np.std(data_in))\n",
    "        axs[4].set_title(f'Norm image', fontsize=12)\n",
    "\n",
    "        axs[5].imshow((data_in - np.mean(data_in<255))/np.std(data_in<255))\n",
    "        axs[5].set_title(f'Norm image (with negative)', fontsize=12)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b90774d-b6e8-4df5-b69a-6db30b62fa35",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_dir = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/zscaled_512_rescaled_SAM_stats/'\n",
    "all_images = []\n",
    "stds_images = []\n",
    "max_mean = 0\n",
    "min_mean = 1000\n",
    "for filename in os.listdir(image_dir):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        image = Image.open(os.path.join(image_dir, filename))\n",
    "\n",
    "        image_array = np.array(image) \n",
    "        max_mean = max(max_mean, np.mean(image_array[image_array>0]))\n",
    "        min_mean = min(min_mean, np.mean(image_array[image_array>0]))\n",
    "        \n",
    "        all_images.append(np.mean(image_array[image_array>0]))\n",
    "        stds_images.append(np.std(image_array[image_array>0]))\n",
    "\n",
    "print('Mean of means all images:', np.mean(all_images)/255.0, ' Std:', np.std(all_images)/255.0)\n",
    "print('Mean of stds all images:', np.mean(stds_images)/255.0, ' Std:', np.std(stds_images)/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac976aa-b53e-4332-b3f3-0b576773ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_images), max_mean/255.0, min_mean/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b9b9f4-2dcb-438f-9e94-c1786385f5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dir_files = [file_ for file_ in os.listdir(output_dir)]\n",
    "\n",
    "# for im_key in img_keys:\n",
    "#     for f in dir_files:\n",
    "#         if im_key in f:\n",
    "#             print(im_key, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0997af",
   "metadata": {},
   "source": [
    "## SAM standard statistics visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d86ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pixel_mean = np.array([123.675, 116.28, 103.53])/255.0 # default values in MobileSAM (RGB)\n",
    "pixel_std = np.array([58.395, 57.12, 57.375])/255.0 # default values in MobileSAM \n",
    "\n",
    "# Generate some data for these values\n",
    "data = [np.clip(np.random.normal(mu, sigma, 1000), 0, 1) for mu, sigma in zip(pixel_mean, pixel_std)]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "colors = ['r', 'g', 'b']\n",
    "labels = ['Red Channel', 'Green Channel', 'Blue Channel']\n",
    "\n",
    "for i in range(3):\n",
    "    ax.hist(data[i], bins=30, alpha=0.5, color=colors[i], label=labels[i])\n",
    "\n",
    "ax.set_title(f'Segment Anything Pixel Intensity Distribution\\n ~x_r = {pixel_mean[0]}, ~x_g = {pixel_mean[1]}, ~x_b = {pixel_mean[2]}\\nσ_r = {pixel_std[0]},  σ_g= {pixel_std[1].round(3)}, σ_b = {pixel_std[2]}')\n",
    "ax.set_xlabel('Pixel Intensity')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66563eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.subplots as sp\n",
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "\n",
    "# t1 = f\" ~x = {np.median(data).round(3)}, ζ_biw = {biweight_location(data).round(3)}<br>ˉx = {np.mean(data).round(3)}, σ = {np.std(data).round(3)}\"\n",
    "# t2 = f\" ~x = {np.median(usual_data).round(3)}, ζ_biw = {biweight_location(usual_data).round(3)}<br>ˉx = {np.mean(usual_data).round(3)}, σ = {np.std(usual_data).round(3)}\"\n",
    "\n",
    "# fig = sp.make_subplots(rows=2, cols=2, vertical_spacing=0.1, subplot_titles=[t1, t2, '', ''])\n",
    "# fig.add_trace(go.Image(z=data), row=1, col=1)\n",
    "# fig.add_trace(go.Image(z=usual_data), row=1, col=2)\n",
    "\n",
    "# fig.add_trace(go.Histogram(x=data_2D.flatten(), nbinsx=100), row=2, col=1)\n",
    "# fig.add_trace(go.Histogram(x=usual_data_2D.flatten(), nbinsx=100), row=2, col=2)\n",
    "# fig.update_layout(height=1000, width=1000, showlegend=False)\n",
    "# fig.write_image(\"plots/statistics_comparison.png\", width=1920, height=1920, scale=2)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e860c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "image = cv2.imread('/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/S0202730101_B.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "gamma = 1.5\n",
    "gamma_corrected = np.uint8(((image / 255.0) ** gamma) * 255.0)\n",
    "\n",
    "# Plot original and gamma-corrected images\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('Original Image')\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title('Gamma-Corrected Image (γ=1.5)')\n",
    "plt.imshow(gamma_corrected, cmap='gray')\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "cv2.imwrite(f'/plots/gamma_.png', gamma_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fde8c-ec77-491e-acce-4870c0c41784",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(image)/255, np.std(image)/255,np.mean(gamma_corrected)/255, np.std(gamma_corrected)/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92195fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# import numpy as np\n",
    "\n",
    "# datasets = {\n",
    "#     \"SA-1B\": np.random.rand(1000, 2),\n",
    "#     \"LVIS v1\": np.random.rand(1000, 2),\n",
    "#     \"COCO\": np.random.rand(1000, 2),\n",
    "#     \"ADE20K\": np.random.rand(1000, 2),\n",
    "#     \"Open Images\": np.random.rand(1000, 2)\n",
    "# }\n",
    "\n",
    "# fig, axes = plt.subplots(1, len(datasets), figsize=(15, 3))\n",
    "\n",
    "# for ax, (title, data) in zip(axes, datasets.items()):\n",
    "#     sns.kdeplot(x=data[:, 0], y=data[:, 1], ax=ax, fill=True, cmap='magma')\n",
    "#     ax.set_title(title)\n",
    "#     ax.axis('off')  \n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "centers_array =  np.array(get_normalized_centers(data_2D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3f8274",
   "metadata": {},
   "source": [
    "# Telescope filter Statistics\n",
    "\n",
    "The usual filters of the Optical Monitor are:\n",
    "* M, U, L, V, B, S, W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7c5251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from astropy.stats import biweight_location\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def calculate_filter_statistics(path, image_files):\n",
    "    group_means = {}\n",
    "    group_stds = {}\n",
    "    group_medians = {}\n",
    "    group_biweight_locs = {}\n",
    "    stds_mean = {}\n",
    "    stds_stds = {}\n",
    "    stds_median = {}\n",
    "    stds_biw = {}\n",
    "    \n",
    "    for group, images in image_files.items():\n",
    "        means = []\n",
    "        stds = []\n",
    "        medians = []\n",
    "        biweight_locs = []\n",
    "\n",
    "        for image_file in images:\n",
    "            new_path = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/'\n",
    "            image = Image.open(os.path.join(new_path, image_file)) \n",
    "            # image = Image.open(os.path.join(path, image_file)) \n",
    "            \n",
    "            image_array = np.array(image)/255.0\n",
    "            positive_pixels = image_array[image_array > 0]\n",
    "            if positive_pixels.size > 1:\n",
    "                means.append(np.mean(positive_pixels))\n",
    "                stds.append(np.std(positive_pixels))\n",
    "                medians.append(np.median(positive_pixels))\n",
    "                biweight_locs.append(biweight_location(positive_pixels))\n",
    "\n",
    "        group_means[group] = np.mean(means)\n",
    "        group_stds[group] = np.mean(stds)\n",
    "        group_medians[group] = np.mean(medians)\n",
    "        group_biweight_locs[group] = np.mean(biweight_locs)\n",
    "\n",
    "        stds_mean[group] = np.std(means)\n",
    "        stds_stds[group] = np.std(stds)\n",
    "        stds_median[group] = np.std(medians)\n",
    "        stds_biw[group] = np.std(biweight_locs)\n",
    "        \n",
    "    # SAM standard statistics\n",
    "    pixel_mean = np.array([123.675, 116.28, 103.53])/255.0\n",
    "    pixel_std = np.array([58.395, 57.12, 57.375])/255.0\n",
    "\n",
    "    # Generate some data\n",
    "    data = [np.clip(np.random.normal(mu, sigma, 1000), 0, 1) for mu, sigma in zip(pixel_mean, pixel_std)]    \n",
    "    colors_sam = ['r', 'g', 'b']\n",
    "    labels = ['Red Channel', 'Green Channel', 'Blue Channel']\n",
    "\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    n = len(group_means)\n",
    "    colors = cm.get_cmap('cool', n)(np.arange(n))\n",
    "    colors[:, -1] = 0.5 \n",
    "\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(30, 7))\n",
    "    \n",
    "    for ax in axs:\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.spines['top'].set_visible(False)\n",
    "        ax.grid(True)\n",
    "        ax.tick_params(axis='x', labelsize=20)  # Set x-axis label size\n",
    "        ax.tick_params(axis='y', labelsize=20)  # Set y-axis label size\n",
    "    \n",
    "    axs[0].bar(range(len(group_means)), list(group_means.values()), yerr=list(stds_mean.values()), \n",
    "           tick_label=list(image_files.keys()), color=colors, capsize=5)\n",
    "    axs[0].axhline(y=0.45, color='red', linestyle='--', linewidth=5) \n",
    "\n",
    "    axs[1].bar(range(len(group_stds.values())), group_stds.values(),  yerr=list(stds_stds.values()), \n",
    "           tick_label=list(image_files.keys()), color=colors, capsize=5)\n",
    "    axs[1].axhline(y=0.22, color='red', linestyle='--', linewidth=5) \n",
    "    \n",
    "    axs[0].set_title('Mean', fontsize=30)\n",
    "    axs[1].set_title('Std', fontsize=30)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('./plots/statistics_XMM_OM_images_vs_SAM.png', dpi=1000)\n",
    "    plt.show()\n",
    "    \n",
    "folder_path = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/zscaled_512_rescaled_SAM_stats/'\n",
    "file_groups = {}\n",
    "\n",
    "k=0\n",
    "for filename in os.listdir(folder_path):\n",
    "    if k<200:\n",
    "        k+=1\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "        if os.path.isfile(file_path) and (filename.endswith(\".jpg\") or filename.endswith(\".png\")) and 'clahe' not in filename:\n",
    "            key = filename.split('.')[0][-1]\n",
    "            if key in file_groups:\n",
    "                file_groups[key].append(file_path)\n",
    "            else:\n",
    "                file_groups[key] = [file_path]\n",
    "\n",
    "calculate_filter_statistics(folder_path, file_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698d0514",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot image-size normalized mask center distribution using kernel density estimation given extracted sources. \n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(5, 5))  # Corrected line\n",
    "\n",
    "# sns.kdeplot(x=centers_array[:, 0], y=centers_array[:, 1], fill=True, ax=ax, cmap='magma', warn_singular=False)\n",
    "# ax.set_title(f'XMM-Newton Optical Monitor\\nImage-size normalized mask center distribution', fontsize=10, fontfamily='monospace')\n",
    "# # ax.axis('off')\n",
    "# ax.set_xlabel(\"norm-X\")\n",
    "# ax.set_ylabel(\"norm-Y\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd4aabd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma clipping\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=3.0)\n",
    "print((mean, median, std))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea622c59",
   "metadata": {},
   "source": [
    "# Source extraction with sigma clipping and background estimation\n",
    "\n",
    "It's necessary to analyse the CDF of the image data in order to choose good sigma values for clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defbda11-a81f-4c4e-8c0f-513df1c4bce7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "\n",
    "def group_files_by_substrings(path, substrings):\n",
    "    all_files = glob.glob(os.path.join(path, '*'))\n",
    "\n",
    "    groups = defaultdict(list)\n",
    "\n",
    "    for file in all_files:\n",
    "        for substring in substrings:\n",
    "            keyy = file.split('/')[-1][12]\n",
    "            if substring in keyy:\n",
    "                groups[substring].append(file)\n",
    "\n",
    "    return groups\n",
    "    \n",
    "path_ = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/zscaled_512_rescaled_SAM_stats/'\n",
    "substrings = ['M', 'U', 'L', 'V', 'B', 'S', 'W']\n",
    "groups = group_files_by_substrings(path_, substrings)\n",
    "\n",
    "# cdfs = defaultdict(list)\n",
    "# for keyy, path_list in groups.items():\n",
    "#     for img_path in path_list:\n",
    "#             image = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#             data_img = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "#             data_2D_img = np.dot(data_img[..., :3], [0.21, 0.72, 0.07])\n",
    "#             data_2D_img = data_2D_img[data_2D_img>0]\n",
    "#             # Calculate the CDF\n",
    "#             sorted_values = np.sort(data_2D_img.flatten())\n",
    "#             cumulative = np.cumsum(sorted_values)  # Cumulative sum\n",
    "#             cdf = cumulative / cumulative[-1]  # Normalization\n",
    "#             cdfs[keyy].append(cdf)\n",
    "\n",
    "#     average_prob = np.mean(cdfs[keyy], axis=0)\n",
    "#     cdfss = np.cumsum(average_prob)\n",
    "#     # print(cdfss)\n",
    "#     # if keyy == 'L':\n",
    "#     plt.plot(sorted_values, cdfss, label=img_path)\n",
    "    \n",
    "#     plt.title(f\"CDFs of Image Pixel Intensities ({keyy} filter)\")\n",
    "#     plt.xlabel(\"Pixel Intensity\")\n",
    "#     plt.ylabel(\"Cumulative Distribution\")\n",
    "#     ax.legend()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig(f'./plots/CDF_filter{keyy}.png', dpi=300)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05480c0-3623-4ed8-97ab-ce85158330d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Log transform x\n",
    "xlog = np.log10(x[1:])  # Exclude the first element because log10(0) is undefined\n",
    "\n",
    "# Create spline\n",
    "spline = UnivariateSpline(xlog, y[1:])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(xlog, spline(xlog), 'b-', lw=2)  # Spline\n",
    "plt.plot(xlog, y[1:], 'ro')  # Original data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640edcae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "def find_changes(cdf):\n",
    "    second_derivative = np.gradient(np.gradient(cdf))\n",
    "    changes_indices = np.where(np.diff(np.sign(second_derivative)))[0]\n",
    "    return changes_indices\n",
    "\n",
    "sorted_values = np.sort(data_2D.flatten())\n",
    "cumulative = np.cumsum(sorted_values)  # Cumulative sum\n",
    "cdf = cumulative / cumulative[-1]  # Normalization\n",
    "\n",
    "plt.plot(sorted_values, cdf)\n",
    "\n",
    "plt.title(f\"CDFs of Image Pixel Intensities\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Cumulative Distribution\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig(f'./plots/CDF_filter{keyy}.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "changes_indices = find_changes(cdf)\n",
    "changes_indices\n",
    "\n",
    "sigma_values = sorted_values[changes_indices]\n",
    "len(sigma_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd559c-e0ab-4bdb-ae07-ef402966a78e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.arange(len(sorted_values))\n",
    "y = sorted_values\n",
    "\n",
    "xlog = np.log10(x[1:]) \n",
    "\n",
    "# Create spline\n",
    "spline = UnivariateSpline(xlog, y[1:])\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(xlog, spline(xlog), 'b-', lw=2)  # Spline\n",
    "plt.plot(xlog, y[1:], 'ro')  # Original data\n",
    "plt.show()\n",
    "\n",
    "# # Compute second derivative\n",
    "# spline_deriv2 = spline.derivative(n=2)\n",
    "\n",
    "# # Find roots of the second derivative\n",
    "# inflexion_points = spline_deriv2.roots()\n",
    "\n",
    "# # Print inflexion points\n",
    "# print(inflexion_points)\n",
    "\n",
    "x = np.linspace(np.min(sorted_values), np.max(sorted_values), num=len(sorted_values))  \n",
    "y = spline(cdf)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.plot(y, 'b-', lw=2)  # Spline\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Find where y-values change sign\n",
    "roots = x[:-1][np.diff(np.sign(y)) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e609faa-4c50-4149-b89d-4cde12def4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "roots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdcb6e3-2c1c-44c1-8904-22d260188d71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from scipy.signal import savgol_filter\n",
    "\n",
    "# smoothed_cdf = savgol_filter(cdf, window_length=5, polyorder=2)\n",
    "\n",
    "# plt.plot(sorted_values, smoothed_cdf)\n",
    "# plt.title(\"Smoothed CDF\")\n",
    "# plt.xlabel(\"Pixel Intensity\")\n",
    "# plt.ylabel(\"Cumulative Distribution\")\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "interp_func = interp1d(sorted_values, cdf, kind='linear')\n",
    "\n",
    "new_sorted_values = np.linspace(sorted_values.min(), sorted_values.max(), 1000)\n",
    "smoothed_cdf = interp_func(new_sorted_values)\n",
    "\n",
    "plt.plot(new_sorted_values, smoothed_cdf)\n",
    "plt.title(\"Interpolated CDF\")\n",
    "plt.xlabel(\"Pixel Intensity\")\n",
    "plt.ylabel(\"Cumulative Distribution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24d0663-3caa-4483-9637-330b8e02fd1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_indices = find_changes(smoothed_cdf)\n",
    "sigma_values = new_sorted_values[changes_indices]\n",
    "len(sigma_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd81c11-00d9-4069-8910-1e3297d7c933",
   "metadata": {},
   "source": [
    "## Source detection and deblend + bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e3ce37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import defaultdict \n",
    "\n",
    "from importlib import reload\n",
    "import astronomy_utils\n",
    "reload(astronomy_utils)\n",
    "from astronomy_utils import *\n",
    "\n",
    "hw_threshold = 5\n",
    "clip_sigmas = [3]\n",
    "kernel_sigma = 1.5\n",
    "npixels = 10\n",
    "sigma_kernel = r\"${\\sigma}_{\\mathrm{kernel}}$\"\n",
    "sigma_clip = r\"${\\sigma}_{\\mathrm{clip}}$\"\n",
    "\n",
    "bboxes = defaultdict(dict)\n",
    "points = defaultdict(dict)\n",
    "\n",
    "input_dir = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/zscaled_512_rescaled_SAM_stats/'\n",
    "# file_name = '/workspace/raid/OM_DeepLearning/XMM_OM_code/scaled_raw/clahe_S0601270201_B.png'\n",
    "\n",
    "if 1==1:\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        if 'clahe' not in file_name and file_name.endswith('.png'):\n",
    "            \n",
    "            image = cv2.imread(input_dir+file_name, cv2.IMREAD_GRAYSCALE)\n",
    "            data = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            data_2D = np.dot(data[..., :3], [0.21, 0.72, 0.07]) \n",
    "            \n",
    "            bboxes[file_name] = [] # some observations may have 0 boxes\n",
    "            points[file_name] = [] \n",
    "                        \n",
    "            for clip_sigma in clip_sigmas:\n",
    "                segment_map, segment_map_finder, sources_tbl_with_hw_threshold = detect_and_deblend_sources(data_2D, hw_threshold=hw_threshold, clip_sigma=clip_sigma, \n",
    "                                                                                    kernel_sigma=kernel_sigma, npixels=npixels, verbose=True)\n",
    "                if sources_tbl_with_hw_threshold is not None:\n",
    "    \n",
    "                    plt.imshow(data_2D, cmap='gray')\n",
    "                    for source in sources_tbl_with_hw_threshold:\n",
    "                        x, y = source['xcentroid'], source['ycentroid']\n",
    "                        semimajor = source['semimajor_sigma'].value * 4\n",
    "                        semiminor = source['semiminor_sigma'].value * 4\n",
    "                        theta = source['orientation'].value \n",
    "                        ellipse = patches.Ellipse((x, y), 2*semimajor, 2*semiminor, angle=theta, \n",
    "                                              edgecolor='green', facecolor='none')\n",
    "                        plt.gca().add_patch(ellipse)\n",
    "                        \n",
    "                        xmin = source['bbox_xmin']-4 # slightly enlarge the bbox \n",
    "                        xmax = source['bbox_xmax']+3\n",
    "                        ymin = source['bbox_ymin']-3\n",
    "                        ymax = source['bbox_ymax']+3\n",
    "            \n",
    "                        width = xmax - xmin\n",
    "                        height = ymax - ymin\n",
    "                        bboxes[file_name].append([int(xmin), int(ymin), int(width), int(height)])\n",
    "                        points[file_name].append([float(x), float(y)])\n",
    "                        \n",
    "                        rect = patches.Rectangle((xmin, ymin), width, height, edgecolor='red', facecolor='none')\n",
    "                        plt.gca().add_patch(rect)\n",
    "                \n",
    "                    plt.title(f'{file_name}\\nsources + bboxes, hidth-witdh > {hw_threshold} px\\n{sigma_clip} = {clip_sigma}, {sigma_kernel} = {kernel_sigma}'+\\\n",
    "                            f', {len(sources_tbl_with_hw_threshold)} bboxes', fontsize=10, fontfamily='monospace')\n",
    "                    plt.colorbar()\n",
    "                    plt.show()\n",
    "                    plt.close()\n",
    "                else:\n",
    "                    print('No sources found at σ =', clip_sigma)\n",
    "if 1==1:\n",
    "    import json\n",
    "    \n",
    "    json_dict = {\"bboxes\": bboxes, \"points\": points}\n",
    "    \n",
    "    with open('extracted_sources_bboxes_points.json', 'w') as f:\n",
    "        json.dump(json_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b89082-95ae-42dc-a816-62fdc68d6997",
   "metadata": {},
   "source": [
    "**one image run**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29f397",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import astronomy_utils\n",
    "reload(astronomy_utils)\n",
    "from astronomy_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from collections import defaultdict \n",
    "\n",
    "file_name = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/S0048740101_B.png'\n",
    "image = cv2.imread(file_name, cv2.IMREAD_COLOR)\n",
    "data = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "data_2D = np.dot(data[..., :3], [0.21, 0.72, 0.07]) \n",
    "\n",
    "bboxes = defaultdict(list)\n",
    "points = defaultdict(list)\n",
    "\n",
    "hw_threshold = 5\n",
    "clip_sigmas = [2]\n",
    "kernel_sigma = 3\n",
    "npixels = 100\n",
    "\n",
    "for clip_sigma in clip_sigmas:\n",
    "    segment_map, segment_map_finder, sources_tbl_with_hw_threshold = detect_and_deblend_sources(data_2D, hw_threshold=hw_threshold, clip_sigma=clip_sigma, \n",
    "                                                                          kernel_sigma=kernel_sigma, npixels=npixels, verbose=True)\n",
    "    if sources_tbl_with_hw_threshold is not None:\n",
    "\n",
    "        plt.imshow(data_2D, cmap='gray')\n",
    "        for source in sources_tbl_with_hw_threshold:\n",
    "            x, y = source['xcentroid'], source['ycentroid']\n",
    "            semimajor = source['semimajor_sigma'].value * 2.5\n",
    "            semiminor = source['semiminor_sigma'].value * 2.5\n",
    "            theta = source['orientation'].value \n",
    "            ellipse = patches.Ellipse((x, y), 2*semimajor, 2*semiminor, angle=theta, \n",
    "                                      edgecolor='green', facecolor='none')\n",
    "            plt.gca().add_patch(ellipse)\n",
    "        \n",
    "            xmin = source['bbox_xmin']-3 # slightly enlarge the bbox \n",
    "            xmax = source['bbox_xmax']+3\n",
    "            ymin = source['bbox_ymin']-3\n",
    "            ymax = source['bbox_ymax']+3\n",
    "\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "            bboxes[file_name].append([int(xmin), int(ymin), int(width), int(height)])\n",
    "            points[file_name].append([float(x), float(y)])\n",
    "            \n",
    "            rect = patches.Rectangle((xmin, ymin), width, height, edgecolor='red', facecolor='none')\n",
    "            plt.gca().add_patch(rect)\n",
    "    \n",
    "        plt.title(f'{file_name.split(\"/\")[-1]}\\nsources + bboxes, hidth-witdh > {hw_threshold} px\\n{sigma_clip} = {clip_sigma}, {sigma_kernel} = {kernel_sigma}'+\\\n",
    "                  f', {len(sources_tbl_with_hw_threshold)} bboxes', fontsize=10, fontfamily='monospace')\n",
    "        plt.colorbar()\n",
    "        plt.savefig('./plots/detected_sources.png', dpi=1000)\n",
    "        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "    else:\n",
    "        print('No sources found at σ =', clip_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61d3ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Median = {np.median(data_2D[data_2D>0])/255.0}. Mean = {np.mean(data_2D[data_2D>0])/255.0}. Std = {np.std(data_2D[data_2D>0])/255.0}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca4e118-5b35-4abf-b4b5-3845479c491b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a02fc1-2194-4af6-a797-aba27fec9681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467b708-2a9d-4e77-9397-dec987e1d7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb53c8c-8453-414f-8c4b-7da5090ff2d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py311",
   "language": "python",
   "name": "env_py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
