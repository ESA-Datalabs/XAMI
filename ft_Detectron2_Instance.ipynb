{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10QrSe6tbogs"
   },
   "source": [
    "inspired from: https://youtu.be/cEgF0YknpZw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewiM3shDabuw"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1, 2, 3' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "FsePPpwZSmqt",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n",
      "Requirement already satisfied: Pillow>=7.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (10.2.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/env_py311/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: pycocotools>=2.0.2 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (2.0.7)\n",
      "Requirement already satisfied: termcolor>=1.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (2.4.0)\n",
      "Requirement already satisfied: yacs>=0.1.8 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (0.1.8)\n",
      "Requirement already satisfied: tabulate in /opt/conda/envs/env_py311/lib/python3.11/site-packages (0.9.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/conda/envs/env_py311/lib/python3.11/site-packages (3.0.0)\n",
      "Requirement already satisfied: tqdm>4.29.0 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (4.66.1)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/envs/env_py311/lib/python3.11/site-packages (2.16.2)\n",
      "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (0.1.9)\n",
      "Requirement already satisfied: omegaconf<2.4,>=2.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (2.3.0)\n",
      "Requirement already satisfied: hydra-core>=1.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: black in /opt/conda/envs/env_py311/lib/python3.11/site-packages (23.12.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/env_py311/lib/python3.11/site-packages (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: PyYAML in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from yacs>=0.1.8) (6.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (1.60.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (4.23.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from tensorboard) (3.0.1)\n",
      "Requirement already satisfied: portalocker in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from iopath<0.1.10,>=0.1.7) (2.8.2)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from black) (8.1.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.4.3 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from black) (1.0.0)\n",
      "Requirement already satisfied: pathspec>=0.9.0 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from black) (0.12.1)\n",
      "Requirement already satisfied: platformdirs>=2 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from black) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/envs/env_py311/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.5)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# !python -m pip install pyyaml==5.1\n",
    "import sys, os, distutils.core\n",
    "# !git clone 'https://github.com/facebookresearch/detectron2'\n",
    "dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n",
    "!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n",
    "sys.path.insert(0, os.path.abspath('./detectron2'))\n",
    "\n",
    "# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Ymh1ZusxDdST",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n",
      "torch:  2.1 ; cuda:  cu121\n",
      "detectron2: 0.6\n"
     ]
    }
   ],
   "source": [
    "import torch, detectron2\n",
    "!nvcc --version\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
    "print(\"detectron2:\", detectron2.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda:3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w3RUzXAwDpmi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matplotlib data path: /opt/conda/envs/env_py311/lib/python3.11/site-packages/matplotlib/mpl-data\n",
      "CONFIGDIR=/root/.config/matplotlib\n",
      "interactive is False\n",
      "platform is linux\n",
      "CACHEDIR=/root/.cache/matplotlib\n",
      "Using fontManager instance from /root/.cache/matplotlib/fontlist-v330.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = 'my_dataset_train5'\n",
    "dataset_val = 'my_dataset_val5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ssw3M-5HFQ3a"
   },
   "outputs": [],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "register_coco_instances(\n",
    "    dataset_train, \n",
    "    {}, \n",
    "    \"./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/train_1/skf_train_annotations.coco.json\", \n",
    "    \"./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/train_1/\")\n",
    "\n",
    "register_coco_instances(\n",
    "    dataset_val, \n",
    "    {}, \n",
    "    \"./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/valid_1/skf_valid_annotations.coco.json\", \n",
    "    \"./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/valid_1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tYOyee79IxHz",
    "outputId": "c1d3ee59-f226-4f88-8a57-fc8105e3e99d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/09 17:00:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/09 17:00:16 d2.data.datasets.coco]: \u001b[0mLoaded 484 images in COCO format from ./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/train_1/skf_train_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "train_metadata = MetadataCatalog.get(dataset_train)\n",
    "train_dataset_dicts = DatasetCatalog.get(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RlG0ZUAwK4cU",
    "outputId": "20c3abed-3ba9-4b26-a264-4557aff8ea0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/09 17:00:16 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/09 17:00:16 d2.data.datasets.coco]: \u001b[0mLoaded 243 images in COCO format from ./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/valid_1/skf_valid_annotations.coco.json\n"
     ]
    }
   ],
   "source": [
    "val_metadata = MetadataCatalog.get(dataset_val)\n",
    "val_dataset_dicts = DatasetCatalog.get(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "PNOR-qZ5LXsU"
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 853
    },
    "id": "nl5b9KPyLRfc",
    "outputId": "516cf1e1-b812-42ac-e070-8e3089f84262",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for d in random.sample(train_dataset_dicts, 2):\n",
    "#     img = cv2.imread(d[\"file_name\"])\n",
    "#     visualizer = Visualizer(img[:, :, ::-1], metadata=train_metadata, scale=0.5)\n",
    "#     vis = visualizer.draw_dataset_dict(d)\n",
    "#     plt.imshow(vis.get_image()[:, :, ::-1])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popen(['git', 'version'], cwd=/workspace/raid/OM_DeepLearning/XMM_OM_code_git, stdin=None, shell=False, universal_newlines=False)\n",
      "Popen(['git', 'version'], cwd=/workspace/raid/OM_DeepLearning/XMM_OM_code_git, stdin=None, shell=False, universal_newlines=False)\n",
      "Trying paths: ['/root/.docker/config.json', '/root/.dockercfg']\n",
      "No config file found\n",
      "[Tracing] Create new propagation context: {'trace_id': '661287c5267148d4b5054c361eef508d', 'span_id': '9a4d8176b9d041c3', 'parent_span_id': None, 'dynamic_sampling_context': None}\n",
      "Starting new HTTP connection (1): localhost:8887\n",
      "http://localhost:8887 \"GET /api/sessions?token= HTTP/1.1\" 403 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new HTTPS connection (1): api.wandb.ai:443\n",
      "https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n",
      "https://api.wandb.ai:443 \"POST /graphql HTTP/1.1\" 200 None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33miuliaelisa15\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "2024-04-09 17:00:18.554379: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Falling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
      "Creating converter from 7 to 5\n",
      "Creating converter from 5 to 7\n",
      "Creating converter from 7 to 5\n",
      "Creating converter from 5 to 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 17:00:19.425964: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Popen(['git', 'cat-file', '--batch-check'], cwd=/workspace/raid/OM_DeepLearning/XMM_OM_code_git, stdin=<valid stream>, shell=False, universal_newlines=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/workspace/raid/OM_DeepLearning/XMM_OM_code_git/wandb/run-20240409_170020-4pjesvnv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/iuliaelisa15/ft_detectron2/runs/4pjesvnv' target=\"_blank\">exalted-puddle-8</a></strong> to <a href='https://wandb.ai/iuliaelisa15/ft_detectron2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/iuliaelisa15/ft_detectron2' target=\"_blank\">https://wandb.ai/iuliaelisa15/ft_detectron2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/iuliaelisa15/ft_detectron2/runs/4pjesvnv' target=\"_blank\">https://wandb.ai/iuliaelisa15/ft_detectron2/runs/4pjesvnv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/iuliaelisa15/ft_detectron2/runs/4pjesvnv?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7fb0529517d0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()\n",
    "wandb.init(project='ft_detectron2', sync_tensorboard=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-iPBoV69LrOE",
    "outputId": "7bcd42e7-4aa4-4ade-fd54-ca745406ee0d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IN GENERALIZED RCNN INIT\n",
      "\u001b[32m[04/09 17:00:41 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=5, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=16, bias=True)\n",
      "    )\n",
      "    (mask_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (mask_head): MaskRCNNConvUpsampleHead(\n",
      "      (mask_fcn1): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn2): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn3): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (mask_fcn4): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (deconv_relu): ReLU()\n",
      "      (predictor): Conv2d(256, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/09 17:00:41 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/09 17:00:41 d2.data.datasets.coco]: \u001b[0mLoaded 484 images in COCO format from ./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/train_1/skf_train_annotations.coco.json\n",
      "\u001b[32m[04/09 17:00:41 d2.data.build]: \u001b[0mRemoved 17 images with no usable annotations. 467 images left.\n",
      "\u001b[32m[04/09 17:00:41 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n",
      "| artefacts  | 0            | central-ring | 319          | smoke-ring | 756          |\n",
      "| star-loop  | 950          |              |              |            |              |\n",
      "|   total    | 2025         |              |              |            |              |\u001b[0m\n",
      "\u001b[32m[04/09 17:00:41 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]\n",
      "\u001b[32m[04/09 17:00:41 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[04/09 17:00:41 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/09 17:00:41 d2.data.common]: \u001b[0mSerializing 467 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/09 17:00:41 d2.data.common]: \u001b[0mSerialized dataset takes 2.24 MiB\n",
      "\u001b[32m[04/09 17:00:41 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=32\n",
      "\u001b[32m[04/09 17:00:41 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n",
      "URL https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl cached in /root/.torch/iopath_cache/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl\n",
      "[Checkpointer] Loading from /root/.torch/iopath_cache/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n",
      "Reading a file from 'Detectron2 Model Zoo'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (5, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (5,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (16, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (16,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (4, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = \"./output_detectron2\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATASETS.TRAIN = (dataset_train,)\n",
    "cfg.DATASETS.TEST = ()\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\") \n",
    "cfg.SOLVER.IMS_PER_BATCH = 32 # BATCH_SIZE\n",
    "cfg.SOLVER.BASE_LR = 0.0003  \n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.PIXEL_MEAN = [38, 38, 38]\n",
    "cfg.MODEL.PIXEL_STD = [1.0, 1.0, 1.0]\n",
    "cfg.SOLVER.BASE_LR_END = 0.0\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 512  \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 4 # number of classes, without the background!\n",
    "cfg.SOLVER.AMP.ENABLED = True\n",
    "cfg.SOLVER.WEIGHT_DECAY = 0.00005\n",
    "cfg.MODEL.DEVICE = 'cuda:0'\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False) #Load a pretrained model if available (resume training) or start training from scratch if no pretrained model is available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrnDImFQ3XVH"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CNE3JZllGHB1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/09 17:00:41 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/env_py311/lib/python3.11/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3526.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/opt/conda/envs/env_py311/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/09 17:01:59 d2.utils.events]: \u001b[0m eta: 4:57:41  iter: 19  total_loss: 3.168  loss_cls: 1.498  loss_box_reg: 0.09642  loss_mask: 0.6925  loss_rpn_cls: 0.8262  loss_rpn_loc: 0.08431    time: 3.5860  last_time: 3.5161  data_time: 0.2723  last_data_time: 0.2370   lr: 5.9943e-06  max_mem: 10241M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 17:02:00.076834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-09 17:02:00.922147: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/09 17:03:12 d2.utils.events]: \u001b[0m eta: 4:59:08  iter: 39  total_loss: 2.74  loss_cls: 1.197  loss_box_reg: 0.1023  loss_mask: 0.69  loss_rpn_cls: 0.7074  loss_rpn_loc: 0.08591    time: 3.6294  last_time: 3.6891  data_time: 0.2400  last_data_time: 0.2411   lr: 1.1988e-05  max_mem: 10270M\n",
      "\u001b[32m[04/09 17:04:26 d2.utils.events]: \u001b[0m eta: 5:00:08  iter: 59  total_loss: 2.03  loss_cls: 0.7228  loss_box_reg: 0.1041  loss_mask: 0.6846  loss_rpn_cls: 0.3945  loss_rpn_loc: 0.08386    time: 3.6477  last_time: 3.6855  data_time: 0.2367  last_data_time: 0.2408   lr: 1.7982e-05  max_mem: 10310M\n",
      "\u001b[32m[04/09 17:05:39 d2.utils.events]: \u001b[0m eta: 4:58:55  iter: 79  total_loss: 1.476  loss_cls: 0.3859  loss_box_reg: 0.1017  loss_mask: 0.6777  loss_rpn_cls: 0.241  loss_rpn_loc: 0.07861    time: 3.6521  last_time: 3.8553  data_time: 0.2390  last_data_time: 0.2313   lr: 2.3976e-05  max_mem: 10335M\n",
      "\u001b[32m[04/09 17:06:53 d2.utils.events]: \u001b[0m eta: 4:58:00  iter: 99  total_loss: 1.298  loss_cls: 0.2449  loss_box_reg: 0.1123  loss_mask: 0.6686  loss_rpn_cls: 0.1985  loss_rpn_loc: 0.07641    time: 3.6558  last_time: 3.6373  data_time: 0.2372  last_data_time: 0.2356   lr: 2.997e-05  max_mem: 10337M\n",
      "\u001b[32m[04/09 17:07:37 d2.utils.events]: \u001b[0m eta: 4:56:29  iter: 119  total_loss: 1.243  loss_cls: 0.2045  loss_box_reg: 0.1154  loss_mask: 0.6563  loss_rpn_cls: 0.1887  loss_rpn_loc: 0.07474    time: 3.4119  last_time: 1.4208  data_time: 0.2540  last_data_time: 0.2438   lr: 3.5964e-05  max_mem: 10343M\n",
      "\u001b[32m[04/09 17:08:07 d2.utils.events]: \u001b[0m eta: 4:54:28  iter: 139  total_loss: 1.211  loss_cls: 0.2059  loss_box_reg: 0.1253  loss_mask: 0.6419  loss_rpn_cls: 0.1663  loss_rpn_loc: 0.07071    time: 3.1361  last_time: 1.8213  data_time: 0.2723  last_data_time: 0.2800   lr: 4.1958e-05  max_mem: 10346M\n",
      "\u001b[32m[04/09 17:08:38 d2.utils.events]: \u001b[0m eta: 4:51:32  iter: 159  total_loss: 1.227  loss_cls: 0.2165  loss_box_reg: 0.1426  loss_mask: 0.6279  loss_rpn_cls: 0.156  loss_rpn_loc: 0.07279    time: 2.9356  last_time: 1.5662  data_time: 0.2635  last_data_time: 0.2577   lr: 4.7952e-05  max_mem: 10354M\n",
      "\u001b[32m[04/09 17:09:30 d2.utils.events]: \u001b[0m eta: 4:49:52  iter: 179  total_loss: 1.18  loss_cls: 0.2212  loss_box_reg: 0.1564  loss_mask: 0.6074  loss_rpn_cls: 0.1442  loss_rpn_loc: 0.06737    time: 2.8959  last_time: 3.6492  data_time: 0.2440  last_data_time: 0.2399   lr: 5.3946e-05  max_mem: 10354M\n",
      "\u001b[32m[04/09 17:10:44 d2.utils.events]: \u001b[0m eta: 4:49:48  iter: 199  total_loss: 1.151  loss_cls: 0.2214  loss_box_reg: 0.1617  loss_mask: 0.5892  loss_rpn_cls: 0.1264  loss_rpn_loc: 0.06545    time: 2.9756  last_time: 3.7089  data_time: 0.2395  last_data_time: 0.2399   lr: 5.994e-05  max_mem: 10354M\n",
      "\u001b[32m[04/09 17:11:58 d2.utils.events]: \u001b[0m eta: 4:49:40  iter: 219  total_loss: 1.144  loss_cls: 0.2342  loss_box_reg: 0.1754  loss_mask: 0.5637  loss_rpn_cls: 0.1185  loss_rpn_loc: 0.06117    time: 3.0437  last_time: 3.6814  data_time: 0.2459  last_data_time: 0.2568   lr: 6.5934e-05  max_mem: 10368M\n",
      "\u001b[32m[04/09 17:13:13 d2.utils.events]: \u001b[0m eta: 4:49:00  iter: 239  total_loss: 1.113  loss_cls: 0.2333  loss_box_reg: 0.1842  loss_mask: 0.5377  loss_rpn_cls: 0.1147  loss_rpn_loc: 0.05998    time: 3.1012  last_time: 3.7164  data_time: 0.2399  last_data_time: 0.2478   lr: 7.1928e-05  max_mem: 10368M\n",
      "\u001b[32m[04/09 17:14:27 d2.utils.events]: \u001b[0m eta: 4:48:11  iter: 259  total_loss: 1.125  loss_cls: 0.2431  loss_box_reg: 0.1975  loss_mask: 0.5101  loss_rpn_cls: 0.1098  loss_rpn_loc: 0.06419    time: 3.1489  last_time: 3.6650  data_time: 0.2395  last_data_time: 0.2350   lr: 7.7922e-05  max_mem: 10370M\n",
      "\u001b[32m[04/09 17:15:14 d2.utils.events]: \u001b[0m eta: 4:46:52  iter: 279  total_loss: 1.099  loss_cls: 0.2428  loss_box_reg: 0.2037  loss_mask: 0.4896  loss_rpn_cls: 0.1037  loss_rpn_loc: 0.06276    time: 3.0902  last_time: 1.2509  data_time: 0.2388  last_data_time: 0.2528   lr: 8.3916e-05  max_mem: 10374M\n",
      "\u001b[32m[04/09 17:15:33 d2.utils.events]: \u001b[0m eta: 4:45:12  iter: 299  total_loss: 1.089  loss_cls: 0.2486  loss_box_reg: 0.2154  loss_mask: 0.4651  loss_rpn_cls: 0.1018  loss_rpn_loc: 0.05765    time: 2.9471  last_time: 0.9538  data_time: 0.2364  last_data_time: 0.2328   lr: 8.991e-05  max_mem: 10378M\n",
      "\u001b[32m[04/09 17:15:53 d2.utils.events]: \u001b[0m eta: 4:43:30  iter: 319  total_loss: 1.052  loss_cls: 0.2405  loss_box_reg: 0.2121  loss_mask: 0.4454  loss_rpn_cls: 0.09919  loss_rpn_loc: 0.05547    time: 2.8229  last_time: 0.9223  data_time: 0.2357  last_data_time: 0.2328   lr: 9.5904e-05  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:16:37 d2.utils.events]: \u001b[0m eta: 4:41:20  iter: 339  total_loss: 1.06  loss_cls: 0.2526  loss_box_reg: 0.234  loss_mask: 0.4208  loss_rpn_cls: 0.09571  loss_rpn_loc: 0.05648    time: 2.7858  last_time: 3.5627  data_time: 0.2378  last_data_time: 0.2376   lr: 0.0001019  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:17:49 d2.utils.events]: \u001b[0m eta: 4:39:37  iter: 359  total_loss: 1.065  loss_cls: 0.2569  loss_box_reg: 0.2464  loss_mask: 0.4077  loss_rpn_cls: 0.09285  loss_rpn_loc: 0.05238    time: 2.8318  last_time: 3.7250  data_time: 0.2377  last_data_time: 0.2310   lr: 0.00010789  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:19:00 d2.utils.events]: \u001b[0m eta: 4:37:39  iter: 379  total_loss: 1.012  loss_cls: 0.2462  loss_box_reg: 0.2425  loss_mask: 0.381  loss_rpn_cls: 0.08636  loss_rpn_loc: 0.05394    time: 2.8698  last_time: 3.5803  data_time: 0.2359  last_data_time: 0.2419   lr: 0.00011389  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:20:11 d2.utils.events]: \u001b[0m eta: 4:35:52  iter: 399  total_loss: 1.016  loss_cls: 0.2535  loss_box_reg: 0.2521  loss_mask: 0.3656  loss_rpn_cls: 0.08481  loss_rpn_loc: 0.05332    time: 2.9050  last_time: 3.5833  data_time: 0.2357  last_data_time: 0.2372   lr: 0.00011988  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:21:24 d2.utils.events]: \u001b[0m eta: 4:34:49  iter: 419  total_loss: 0.9612  loss_cls: 0.2392  loss_box_reg: 0.2473  loss_mask: 0.3453  loss_rpn_cls: 0.07701  loss_rpn_loc: 0.0528    time: 2.9396  last_time: 3.5651  data_time: 0.2427  last_data_time: 0.2371   lr: 0.00012587  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:22:37 d2.utils.events]: \u001b[0m eta: 4:34:15  iter: 439  total_loss: 0.9628  loss_cls: 0.2468  loss_box_reg: 0.2582  loss_mask: 0.3279  loss_rpn_cls: 0.0717  loss_rpn_loc: 0.05577    time: 2.9724  last_time: 3.7171  data_time: 0.2381  last_data_time: 0.2350   lr: 0.00013187  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:23:50 d2.utils.events]: \u001b[0m eta: 4:33:24  iter: 459  total_loss: 0.9706  loss_cls: 0.2437  loss_box_reg: 0.2595  loss_mask: 0.3201  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.05303    time: 3.0024  last_time: 3.7209  data_time: 0.2478  last_data_time: 0.2931   lr: 0.00013786  max_mem: 10379M\n",
      "\u001b[32m[04/09 17:25:04 d2.utils.events]: \u001b[0m eta: 4:32:26  iter: 479  total_loss: 0.9177  loss_cls: 0.2323  loss_box_reg: 0.2519  loss_mask: 0.3103  loss_rpn_cls: 0.07513  loss_rpn_loc: 0.05309    time: 3.0311  last_time: 3.6549  data_time: 0.2377  last_data_time: 0.2313   lr: 0.00014386  max_mem: 10459M\n",
      "\u001b[32m[04/09 17:26:18 d2.utils.events]: \u001b[0m eta: 4:31:26  iter: 499  total_loss: 0.9095  loss_cls: 0.2342  loss_box_reg: 0.2568  loss_mask: 0.2986  loss_rpn_cls: 0.0659  loss_rpn_loc: 0.04662    time: 3.0578  last_time: 3.6620  data_time: 0.2372  last_data_time: 0.2379   lr: 0.00014985  max_mem: 10459M\n",
      "\u001b[32m[04/09 17:27:31 d2.utils.events]: \u001b[0m eta: 4:30:28  iter: 519  total_loss: 0.9249  loss_cls: 0.2403  loss_box_reg: 0.2697  loss_mask: 0.2981  loss_rpn_cls: 0.06333  loss_rpn_loc: 0.04699    time: 3.0811  last_time: 3.8464  data_time: 0.2395  last_data_time: 0.2453   lr: 0.00015584  max_mem: 10459M\n",
      "\u001b[32m[04/09 17:28:44 d2.utils.events]: \u001b[0m eta: 4:29:32  iter: 539  total_loss: 0.8648  loss_cls: 0.2239  loss_box_reg: 0.2584  loss_mask: 0.2908  loss_rpn_cls: 0.05645  loss_rpn_loc: 0.04392    time: 3.1027  last_time: 3.6984  data_time: 0.2368  last_data_time: 0.2393   lr: 0.00016184  max_mem: 10459M\n",
      "\u001b[32m[04/09 17:29:59 d2.utils.events]: \u001b[0m eta: 4:28:41  iter: 559  total_loss: 0.8581  loss_cls: 0.2184  loss_box_reg: 0.2537  loss_mask: 0.2824  loss_rpn_cls: 0.05517  loss_rpn_loc: 0.04514    time: 3.1248  last_time: 3.6271  data_time: 0.2443  last_data_time: 0.2435   lr: 0.00016783  max_mem: 10459M\n",
      "\u001b[32m[04/09 17:31:12 d2.utils.events]: \u001b[0m eta: 4:27:32  iter: 579  total_loss: 0.8599  loss_cls: 0.2169  loss_box_reg: 0.2582  loss_mask: 0.2831  loss_rpn_cls: 0.05624  loss_rpn_loc: 0.04551    time: 3.1436  last_time: 3.6636  data_time: 0.2507  last_data_time: 0.2434   lr: 0.00017383  max_mem: 10510M\n",
      "\u001b[32m[04/09 17:32:26 d2.utils.events]: \u001b[0m eta: 4:26:33  iter: 599  total_loss: 0.841  loss_cls: 0.2093  loss_box_reg: 0.2544  loss_mask: 0.2789  loss_rpn_cls: 0.05662  loss_rpn_loc: 0.04696    time: 3.1616  last_time: 3.6418  data_time: 0.2542  last_data_time: 0.2424   lr: 0.00017982  max_mem: 10510M\n",
      "\u001b[32m[04/09 17:33:40 d2.utils.events]: \u001b[0m eta: 4:25:24  iter: 619  total_loss: 0.8458  loss_cls: 0.2104  loss_box_reg: 0.2597  loss_mask: 0.2647  loss_rpn_cls: 0.05569  loss_rpn_loc: 0.04703    time: 3.1784  last_time: 3.9450  data_time: 0.2441  last_data_time: 0.2441   lr: 0.00018581  max_mem: 10510M\n",
      "\u001b[32m[04/09 17:34:53 d2.utils.events]: \u001b[0m eta: 4:24:11  iter: 639  total_loss: 0.7928  loss_cls: 0.1949  loss_box_reg: 0.2399  loss_mask: 0.2696  loss_rpn_cls: 0.04735  loss_rpn_loc: 0.04337    time: 3.1936  last_time: 3.7160  data_time: 0.2416  last_data_time: 0.2410   lr: 0.00019181  max_mem: 10798M\n",
      "\u001b[32m[04/09 17:36:07 d2.utils.events]: \u001b[0m eta: 4:23:03  iter: 659  total_loss: 0.7815  loss_cls: 0.1923  loss_box_reg: 0.2335  loss_mask: 0.2654  loss_rpn_cls: 0.0493  loss_rpn_loc: 0.0401    time: 3.2093  last_time: 3.6743  data_time: 0.2475  last_data_time: 0.2475   lr: 0.0001978  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:37:20 d2.utils.events]: \u001b[0m eta: 4:21:53  iter: 679  total_loss: 0.7712  loss_cls: 0.1848  loss_box_reg: 0.2365  loss_mask: 0.2603  loss_rpn_cls: 0.04753  loss_rpn_loc: 0.04093    time: 3.2227  last_time: 3.3325  data_time: 0.2426  last_data_time: 0.2492   lr: 0.0002038  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:37:52 d2.utils.events]: \u001b[0m eta: 4:20:33  iter: 699  total_loss: 0.7954  loss_cls: 0.1906  loss_box_reg: 0.2339  loss_mask: 0.2587  loss_rpn_cls: 0.05005  loss_rpn_loc: 0.04661    time: 3.1751  last_time: 1.4965  data_time: 0.2895  last_data_time: 0.3095   lr: 0.00020979  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:38:22 d2.utils.events]: \u001b[0m eta: 4:19:11  iter: 719  total_loss: 0.7263  loss_cls: 0.1732  loss_box_reg: 0.2215  loss_mask: 0.2521  loss_rpn_cls: 0.04547  loss_rpn_loc: 0.04246    time: 3.1296  last_time: 1.6899  data_time: 0.2893  last_data_time: 0.3354   lr: 0.00021578  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:38:54 d2.utils.events]: \u001b[0m eta: 4:17:48  iter: 739  total_loss: 0.7333  loss_cls: 0.1697  loss_box_reg: 0.2123  loss_mask: 0.254  loss_rpn_cls: 0.04496  loss_rpn_loc: 0.04013    time: 3.0876  last_time: 1.5725  data_time: 0.2997  last_data_time: 0.2966   lr: 0.00022178  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:39:25 d2.utils.events]: \u001b[0m eta: 4:16:23  iter: 759  total_loss: 0.7183  loss_cls: 0.1628  loss_box_reg: 0.2051  loss_mask: 0.2453  loss_rpn_cls: 0.03769  loss_rpn_loc: 0.04005    time: 3.0472  last_time: 1.5274  data_time: 0.2900  last_data_time: 0.3183   lr: 0.00022777  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:39:56 d2.utils.events]: \u001b[0m eta: 4:14:48  iter: 779  total_loss: 0.69  loss_cls: 0.1662  loss_box_reg: 0.2035  loss_mask: 0.2401  loss_rpn_cls: 0.04059  loss_rpn_loc: 0.04019    time: 3.0082  last_time: 1.5587  data_time: 0.2893  last_data_time: 0.3034   lr: 0.00023377  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:40:26 d2.utils.events]: \u001b[0m eta: 4:13:17  iter: 799  total_loss: 0.6701  loss_cls: 0.1591  loss_box_reg: 0.1968  loss_mask: 0.242  loss_rpn_cls: 0.03604  loss_rpn_loc: 0.03725    time: 2.9712  last_time: 1.5330  data_time: 0.2979  last_data_time: 0.2973   lr: 0.00023976  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:40:57 d2.utils.events]: \u001b[0m eta: 4:11:53  iter: 819  total_loss: 0.6732  loss_cls: 0.1551  loss_box_reg: 0.2004  loss_mask: 0.2392  loss_rpn_cls: 0.03644  loss_rpn_loc: 0.03817    time: 2.9364  last_time: 1.5453  data_time: 0.2956  last_data_time: 0.2998   lr: 0.00024575  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:41:28 d2.utils.events]: \u001b[0m eta: 4:10:29  iter: 839  total_loss: 0.665  loss_cls: 0.1522  loss_box_reg: 0.1928  loss_mask: 0.2366  loss_rpn_cls: 0.03667  loss_rpn_loc: 0.03916    time: 2.9032  last_time: 1.5407  data_time: 0.2903  last_data_time: 0.2942   lr: 0.00025175  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:41:59 d2.utils.events]: \u001b[0m eta: 4:09:03  iter: 859  total_loss: 0.637  loss_cls: 0.1482  loss_box_reg: 0.198  loss_mask: 0.2341  loss_rpn_cls: 0.03657  loss_rpn_loc: 0.03559    time: 2.8716  last_time: 1.4630  data_time: 0.2946  last_data_time: 0.2826   lr: 0.00025774  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:42:30 d2.utils.events]: \u001b[0m eta: 4:07:25  iter: 879  total_loss: 0.6239  loss_cls: 0.1397  loss_box_reg: 0.1818  loss_mask: 0.2295  loss_rpn_cls: 0.03  loss_rpn_loc: 0.03536    time: 2.8417  last_time: 1.5535  data_time: 0.2959  last_data_time: 0.3060   lr: 0.00026374  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:43:01 d2.utils.events]: \u001b[0m eta: 4:05:50  iter: 899  total_loss: 0.6325  loss_cls: 0.1438  loss_box_reg: 0.1929  loss_mask: 0.2295  loss_rpn_cls: 0.02884  loss_rpn_loc: 0.03639    time: 2.8124  last_time: 1.4938  data_time: 0.2668  last_data_time: 0.2622   lr: 0.00026973  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:43:32 d2.utils.events]: \u001b[0m eta: 4:04:20  iter: 919  total_loss: 0.6211  loss_cls: 0.1369  loss_box_reg: 0.1869  loss_mask: 0.2269  loss_rpn_cls: 0.03288  loss_rpn_loc: 0.03539    time: 2.7852  last_time: 1.5167  data_time: 0.2629  last_data_time: 0.3089   lr: 0.00027572  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:44:03 d2.utils.events]: \u001b[0m eta: 4:02:51  iter: 939  total_loss: 0.6178  loss_cls: 0.1296  loss_box_reg: 0.1908  loss_mask: 0.2281  loss_rpn_cls: 0.03366  loss_rpn_loc: 0.03746    time: 2.7586  last_time: 1.4930  data_time: 0.2733  last_data_time: 0.2629   lr: 0.00028172  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:44:34 d2.utils.events]: \u001b[0m eta: 4:01:18  iter: 959  total_loss: 0.5948  loss_cls: 0.1291  loss_box_reg: 0.1779  loss_mask: 0.2241  loss_rpn_cls: 0.02936  loss_rpn_loc: 0.03824    time: 2.7335  last_time: 1.5727  data_time: 0.2620  last_data_time: 0.2716   lr: 0.00028771  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:45:05 d2.utils.events]: \u001b[0m eta: 3:59:49  iter: 979  total_loss: 0.6063  loss_cls: 0.1326  loss_box_reg: 0.186  loss_mask: 0.2237  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.04024    time: 2.7090  last_time: 1.4773  data_time: 0.2592  last_data_time: 0.2431   lr: 0.00029371  max_mem: 10865M\n",
      "\u001b[32m[04/09 17:45:29 d2.utils.events]: \u001b[0m eta: 3:57:49  iter: 999  total_loss: 0.6267  loss_cls: 0.1354  loss_box_reg: 0.1954  loss_mask: 0.2228  loss_rpn_cls: 0.02877  loss_rpn_loc: 0.03805    time: 2.6794  last_time: 1.0333  data_time: 0.2453  last_data_time: 0.2460   lr: 0.0002997  max_mem: 10882M\n",
      "\u001b[32m[04/09 17:45:50 d2.utils.events]: \u001b[0m eta: 3:56:10  iter: 1019  total_loss: 0.5826  loss_cls: 0.1234  loss_box_reg: 0.175  loss_mask: 0.224  loss_rpn_cls: 0.02792  loss_rpn_loc: 0.03212    time: 2.6474  last_time: 1.0628  data_time: 0.2405  last_data_time: 0.2412   lr: 0.0003  max_mem: 10982M\n",
      "\u001b[32m[04/09 17:46:12 d2.utils.events]: \u001b[0m eta: 3:51:58  iter: 1039  total_loss: 0.5902  loss_cls: 0.1298  loss_box_reg: 0.1856  loss_mask: 0.2146  loss_rpn_cls: 0.02665  loss_rpn_loc: 0.03425    time: 2.6167  last_time: 1.0334  data_time: 0.2395  last_data_time: 0.2347   lr: 0.0003  max_mem: 11159M\n",
      "\u001b[32m[04/09 17:46:32 d2.utils.events]: \u001b[0m eta: 2:06:00  iter: 1059  total_loss: 0.5759  loss_cls: 0.1206  loss_box_reg: 0.1793  loss_mask: 0.2176  loss_rpn_cls: 0.02466  loss_rpn_loc: 0.03224    time: 2.5867  last_time: 1.0487  data_time: 0.2411  last_data_time: 0.2419   lr: 0.0003  max_mem: 11159M\n",
      "\u001b[32m[04/09 17:46:53 d2.utils.events]: \u001b[0m eta: 1:56:31  iter: 1079  total_loss: 0.5626  loss_cls: 0.1188  loss_box_reg: 0.1782  loss_mask: 0.2151  loss_rpn_cls: 0.02408  loss_rpn_loc: 0.03173    time: 2.5582  last_time: 0.9848  data_time: 0.2390  last_data_time: 0.2321   lr: 0.0003  max_mem: 11159M\n",
      "\u001b[32m[04/09 17:47:15 d2.utils.events]: \u001b[0m eta: 1:46:03  iter: 1099  total_loss: 0.5682  loss_cls: 0.121  loss_box_reg: 0.1828  loss_mask: 0.2135  loss_rpn_cls: 0.02436  loss_rpn_loc: 0.03404    time: 2.5309  last_time: 1.0306  data_time: 0.2442  last_data_time: 0.2374   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:47:38 d2.utils.events]: \u001b[0m eta: 1:44:05  iter: 1119  total_loss: 0.5537  loss_cls: 0.12  loss_box_reg: 0.1757  loss_mask: 0.2048  loss_rpn_cls: 0.02304  loss_rpn_loc: 0.03426    time: 2.5062  last_time: 1.0489  data_time: 0.2425  last_data_time: 0.2365   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:47:59 d2.utils.events]: \u001b[0m eta: 1:43:22  iter: 1139  total_loss: 0.5736  loss_cls: 0.1183  loss_box_reg: 0.1802  loss_mask: 0.2129  loss_rpn_cls: 0.02383  loss_rpn_loc: 0.03313    time: 2.4808  last_time: 1.0564  data_time: 0.2440  last_data_time: 0.2640   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:48:20 d2.utils.events]: \u001b[0m eta: 1:42:38  iter: 1159  total_loss: 0.5689  loss_cls: 0.1199  loss_box_reg: 0.1809  loss_mask: 0.2089  loss_rpn_cls: 0.0207  loss_rpn_loc: 0.03465    time: 2.4561  last_time: 1.0528  data_time: 0.2447  last_data_time: 0.2504   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:48:41 d2.utils.events]: \u001b[0m eta: 1:40:58  iter: 1179  total_loss: 0.5631  loss_cls: 0.1227  loss_box_reg: 0.1807  loss_mask: 0.2111  loss_rpn_cls: 0.02318  loss_rpn_loc: 0.03541    time: 2.4323  last_time: 1.0405  data_time: 0.2411  last_data_time: 0.2380   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:49:02 d2.utils.events]: \u001b[0m eta: 1:39:40  iter: 1199  total_loss: 0.5626  loss_cls: 0.1194  loss_box_reg: 0.1802  loss_mask: 0.2084  loss_rpn_cls: 0.02174  loss_rpn_loc: 0.03326    time: 2.4093  last_time: 1.0455  data_time: 0.2396  last_data_time: 0.2512   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:49:23 d2.utils.events]: \u001b[0m eta: 1:38:11  iter: 1219  total_loss: 0.5588  loss_cls: 0.115  loss_box_reg: 0.1811  loss_mask: 0.2035  loss_rpn_cls: 0.0183  loss_rpn_loc: 0.03163    time: 2.3872  last_time: 1.0679  data_time: 0.2443  last_data_time: 0.2519   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:49:45 d2.utils.events]: \u001b[0m eta: 1:36:52  iter: 1239  total_loss: 0.559  loss_cls: 0.116  loss_box_reg: 0.1823  loss_mask: 0.2049  loss_rpn_cls: 0.0205  loss_rpn_loc: 0.03598    time: 2.3660  last_time: 1.0918  data_time: 0.2424  last_data_time: 0.2589   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:50:06 d2.utils.events]: \u001b[0m eta: 1:35:44  iter: 1259  total_loss: 0.5469  loss_cls: 0.1173  loss_box_reg: 0.1837  loss_mask: 0.2041  loss_rpn_cls: 0.0211  loss_rpn_loc: 0.03334    time: 2.3453  last_time: 1.3142  data_time: 0.2445  last_data_time: 0.2533   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:50:51 d2.utils.events]: \u001b[0m eta: 1:35:10  iter: 1279  total_loss: 0.5475  loss_cls: 0.1129  loss_box_reg: 0.1695  loss_mask: 0.2041  loss_rpn_cls: 0.01949  loss_rpn_loc: 0.03442    time: 2.3438  last_time: 3.8084  data_time: 0.2402  last_data_time: 0.2422   lr: 0.0003  max_mem: 11225M\n",
      "\u001b[32m[04/09 17:52:07 d2.utils.events]: \u001b[0m eta: 1:35:19  iter: 1299  total_loss: 0.5427  loss_cls: 0.1134  loss_box_reg: 0.1745  loss_mask: 0.2043  loss_rpn_cls: 0.02068  loss_rpn_loc: 0.03187    time: 2.3657  last_time: 3.7248  data_time: 0.2438  last_data_time: 0.2445   lr: 0.0003  max_mem: 11429M\n",
      "\u001b[32m[04/09 17:53:22 d2.utils.events]: \u001b[0m eta: 1:35:35  iter: 1319  total_loss: 0.553  loss_cls: 0.1152  loss_box_reg: 0.181  loss_mask: 0.2012  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.03114    time: 2.3868  last_time: 3.7405  data_time: 0.2447  last_data_time: 0.2404   lr: 0.0003  max_mem: 11429M\n",
      "\u001b[32m[04/09 17:54:37 d2.utils.events]: \u001b[0m eta: 1:35:24  iter: 1339  total_loss: 0.5283  loss_cls: 0.1127  loss_box_reg: 0.1685  loss_mask: 0.1973  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.03022    time: 2.4070  last_time: 3.7941  data_time: 0.2422  last_data_time: 0.2531   lr: 0.0003  max_mem: 11429M\n",
      "\u001b[32m[04/09 17:55:52 d2.utils.events]: \u001b[0m eta: 1:34:52  iter: 1359  total_loss: 0.5534  loss_cls: 0.1144  loss_box_reg: 0.1793  loss_mask: 0.1998  loss_rpn_cls: 0.01989  loss_rpn_loc: 0.03377    time: 2.4269  last_time: 3.7440  data_time: 0.2432  last_data_time: 0.2336   lr: 0.0003  max_mem: 11429M\n",
      "\u001b[32m[04/09 17:57:07 d2.utils.events]: \u001b[0m eta: 1:34:21  iter: 1379  total_loss: 0.5296  loss_cls: 0.1101  loss_box_reg: 0.1712  loss_mask: 0.2008  loss_rpn_cls: 0.01853  loss_rpn_loc: 0.03295    time: 2.4461  last_time: 3.7833  data_time: 0.2417  last_data_time: 0.2354   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 17:58:22 d2.utils.events]: \u001b[0m eta: 1:33:50  iter: 1399  total_loss: 0.5323  loss_cls: 0.1101  loss_box_reg: 0.1734  loss_mask: 0.1998  loss_rpn_cls: 0.01873  loss_rpn_loc: 0.03243    time: 2.4649  last_time: 3.7907  data_time: 0.2410  last_data_time: 0.2512   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 17:59:37 d2.utils.events]: \u001b[0m eta: 1:33:19  iter: 1419  total_loss: 0.5358  loss_cls: 0.1075  loss_box_reg: 0.1735  loss_mask: 0.1972  loss_rpn_cls: 0.01706  loss_rpn_loc: 0.03092    time: 2.4832  last_time: 3.8060  data_time: 0.2411  last_data_time: 0.2486   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:00:53 d2.utils.events]: \u001b[0m eta: 1:32:47  iter: 1439  total_loss: 0.5277  loss_cls: 0.1079  loss_box_reg: 0.1707  loss_mask: 0.1967  loss_rpn_cls: 0.01825  loss_rpn_loc: 0.03209    time: 2.5009  last_time: 3.6940  data_time: 0.2452  last_data_time: 0.2416   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:02:07 d2.utils.events]: \u001b[0m eta: 1:32:16  iter: 1459  total_loss: 0.5366  loss_cls: 0.1061  loss_box_reg: 0.1728  loss_mask: 0.1995  loss_rpn_cls: 0.01693  loss_rpn_loc: 0.03389    time: 2.5180  last_time: 3.7431  data_time: 0.2400  last_data_time: 0.2507   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:03:23 d2.utils.events]: \u001b[0m eta: 1:31:45  iter: 1479  total_loss: 0.5322  loss_cls: 0.1063  loss_box_reg: 0.1764  loss_mask: 0.1984  loss_rpn_cls: 0.01973  loss_rpn_loc: 0.0294    time: 2.5349  last_time: 3.7624  data_time: 0.2390  last_data_time: 0.2397   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:04:39 d2.utils.events]: \u001b[0m eta: 1:31:13  iter: 1499  total_loss: 0.5271  loss_cls: 0.1046  loss_box_reg: 0.1787  loss_mask: 0.1944  loss_rpn_cls: 0.01684  loss_rpn_loc: 0.02844    time: 2.5511  last_time: 3.6535  data_time: 0.2406  last_data_time: 0.2462   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:05:54 d2.utils.events]: \u001b[0m eta: 1:30:42  iter: 1519  total_loss: 0.5294  loss_cls: 0.1079  loss_box_reg: 0.1707  loss_mask: 0.194  loss_rpn_cls: 0.01779  loss_rpn_loc: 0.03258    time: 2.5670  last_time: 3.7434  data_time: 0.2421  last_data_time: 0.2375   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:07:10 d2.utils.events]: \u001b[0m eta: 1:30:11  iter: 1539  total_loss: 0.5125  loss_cls: 0.1044  loss_box_reg: 0.1667  loss_mask: 0.1949  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.03126    time: 2.5830  last_time: 3.7745  data_time: 0.2400  last_data_time: 0.2312   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:08:26 d2.utils.events]: \u001b[0m eta: 1:29:40  iter: 1559  total_loss: 0.5258  loss_cls: 0.1058  loss_box_reg: 0.1701  loss_mask: 0.1918  loss_rpn_cls: 0.01406  loss_rpn_loc: 0.03068    time: 2.5985  last_time: 3.8257  data_time: 0.2387  last_data_time: 0.2347   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:09:42 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 1579  total_loss: 0.5165  loss_cls: 0.1022  loss_box_reg: 0.1707  loss_mask: 0.1911  loss_rpn_cls: 0.01652  loss_rpn_loc: 0.03302    time: 2.6137  last_time: 3.8188  data_time: 0.2423  last_data_time: 0.2452   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:10:57 d2.utils.events]: \u001b[0m eta: 1:28:37  iter: 1599  total_loss: 0.5005  loss_cls: 0.1009  loss_box_reg: 0.1595  loss_mask: 0.1916  loss_rpn_cls: 0.01667  loss_rpn_loc: 0.02914    time: 2.6279  last_time: 3.7098  data_time: 0.2351  last_data_time: 0.2345   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:11:52 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 1619  total_loss: 0.5159  loss_cls: 0.1022  loss_box_reg: 0.1695  loss_mask: 0.1902  loss_rpn_cls: 0.01608  loss_rpn_loc: 0.03247    time: 2.6298  last_time: 1.9296  data_time: 0.2547  last_data_time: 0.2973   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:12:24 d2.utils.events]: \u001b[0m eta: 1:27:14  iter: 1639  total_loss: 0.5024  loss_cls: 0.103  loss_box_reg: 0.1662  loss_mask: 0.1916  loss_rpn_cls: 0.01478  loss_rpn_loc: 0.03169    time: 2.6172  last_time: 1.5383  data_time: 0.2752  last_data_time: 0.2546   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:12:56 d2.utils.events]: \u001b[0m eta: 1:26:31  iter: 1659  total_loss: 0.507  loss_cls: 0.1061  loss_box_reg: 0.1639  loss_mask: 0.1922  loss_rpn_cls: 0.01624  loss_rpn_loc: 0.02933    time: 2.6050  last_time: 1.5713  data_time: 0.2698  last_data_time: 0.2670   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:13:28 d2.utils.events]: \u001b[0m eta: 1:25:54  iter: 1679  total_loss: 0.4956  loss_cls: 0.1008  loss_box_reg: 0.1669  loss_mask: 0.1905  loss_rpn_cls: 0.01558  loss_rpn_loc: 0.02932    time: 2.5930  last_time: 1.5571  data_time: 0.2698  last_data_time: 0.2730   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:14:00 d2.utils.events]: \u001b[0m eta: 1:25:29  iter: 1699  total_loss: 0.506  loss_cls: 0.1008  loss_box_reg: 0.1681  loss_mask: 0.186  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.03105    time: 2.5813  last_time: 1.5702  data_time: 0.2694  last_data_time: 0.2755   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:14:33 d2.utils.events]: \u001b[0m eta: 1:25:13  iter: 1719  total_loss: 0.5006  loss_cls: 0.1021  loss_box_reg: 0.1694  loss_mask: 0.1947  loss_rpn_cls: 0.01521  loss_rpn_loc: 0.03029    time: 2.5701  last_time: 1.5830  data_time: 0.2818  last_data_time: 0.2703   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:15:05 d2.utils.events]: \u001b[0m eta: 1:24:53  iter: 1739  total_loss: 0.4999  loss_cls: 0.1015  loss_box_reg: 0.164  loss_mask: 0.1864  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.02805    time: 2.5591  last_time: 1.5665  data_time: 0.2675  last_data_time: 0.2543   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:15:38 d2.utils.events]: \u001b[0m eta: 1:24:35  iter: 1759  total_loss: 0.5132  loss_cls: 0.1056  loss_box_reg: 0.1732  loss_mask: 0.187  loss_rpn_cls: 0.01461  loss_rpn_loc: 0.02958    time: 2.5487  last_time: 1.6217  data_time: 0.2550  last_data_time: 0.2547   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:16:09 d2.utils.events]: \u001b[0m eta: 1:24:16  iter: 1779  total_loss: 0.4945  loss_cls: 0.09611  loss_box_reg: 0.1597  loss_mask: 0.1844  loss_rpn_cls: 0.01412  loss_rpn_loc: 0.02691    time: 2.5375  last_time: 2.1177  data_time: 0.2506  last_data_time: 0.2456   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:16:31 d2.utils.events]: \u001b[0m eta: 1:23:41  iter: 1799  total_loss: 0.4967  loss_cls: 0.09672  loss_box_reg: 0.166  loss_mask: 0.1888  loss_rpn_cls: 0.01539  loss_rpn_loc: 0.03176    time: 2.5211  last_time: 1.0055  data_time: 0.2345  last_data_time: 0.2269   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:16:52 d2.utils.events]: \u001b[0m eta: 1:22:58  iter: 1819  total_loss: 0.486  loss_cls: 0.09893  loss_box_reg: 0.1634  loss_mask: 0.1869  loss_rpn_cls: 0.01306  loss_rpn_loc: 0.02983    time: 2.5051  last_time: 1.0277  data_time: 0.2388  last_data_time: 0.2340   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:17:13 d2.utils.events]: \u001b[0m eta: 1:22:21  iter: 1839  total_loss: 0.4723  loss_cls: 0.09256  loss_box_reg: 0.154  loss_mask: 0.1868  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.0307    time: 2.4893  last_time: 1.2904  data_time: 0.2373  last_data_time: 0.2439   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:17:34 d2.utils.events]: \u001b[0m eta: 1:21:37  iter: 1859  total_loss: 0.4909  loss_cls: 0.09334  loss_box_reg: 0.1684  loss_mask: 0.1866  loss_rpn_cls: 0.01303  loss_rpn_loc: 0.02656    time: 2.4739  last_time: 1.0448  data_time: 0.2419  last_data_time: 0.2559   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:17:56 d2.utils.events]: \u001b[0m eta: 1:20:49  iter: 1879  total_loss: 0.515  loss_cls: 0.1048  loss_box_reg: 0.171  loss_mask: 0.187  loss_rpn_cls: 0.01386  loss_rpn_loc: 0.03288    time: 2.4590  last_time: 1.0825  data_time: 0.2406  last_data_time: 0.2295   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:18:17 d2.utils.events]: \u001b[0m eta: 1:20:14  iter: 1899  total_loss: 0.4859  loss_cls: 0.0966  loss_box_reg: 0.1587  loss_mask: 0.1851  loss_rpn_cls: 0.0127  loss_rpn_loc: 0.02965    time: 2.4444  last_time: 1.0406  data_time: 0.2386  last_data_time: 0.2374   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:18:39 d2.utils.events]: \u001b[0m eta: 1:19:24  iter: 1919  total_loss: 0.4943  loss_cls: 0.09602  loss_box_reg: 0.1625  loss_mask: 0.1834  loss_rpn_cls: 0.01401  loss_rpn_loc: 0.03195    time: 2.4300  last_time: 1.0618  data_time: 0.2348  last_data_time: 0.2367   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:19:01 d2.utils.events]: \u001b[0m eta: 1:18:31  iter: 1939  total_loss: 0.4902  loss_cls: 0.09799  loss_box_reg: 0.1645  loss_mask: 0.182  loss_rpn_cls: 0.01332  loss_rpn_loc: 0.02964    time: 2.4165  last_time: 2.2011  data_time: 0.2336  last_data_time: 0.2405   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:20:17 d2.utils.events]: \u001b[0m eta: 1:18:40  iter: 1959  total_loss: 0.4766  loss_cls: 0.09447  loss_box_reg: 0.1631  loss_mask: 0.1824  loss_rpn_cls: 0.01249  loss_rpn_loc: 0.02902    time: 2.4306  last_time: 3.7821  data_time: 0.2395  last_data_time: 0.2384   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:21:32 d2.utils.events]: \u001b[0m eta: 1:18:48  iter: 1979  total_loss: 0.471  loss_cls: 0.09355  loss_box_reg: 0.1549  loss_mask: 0.1775  loss_rpn_cls: 0.01325  loss_rpn_loc: 0.0282    time: 2.4442  last_time: 3.5051  data_time: 0.2425  last_data_time: 0.2442   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:22:48 d2.utils.events]: \u001b[0m eta: 1:18:51  iter: 1999  total_loss: 0.4821  loss_cls: 0.09256  loss_box_reg: 0.1621  loss_mask: 0.1816  loss_rpn_cls: 0.01328  loss_rpn_loc: 0.02869    time: 2.4574  last_time: 3.7540  data_time: 0.2387  last_data_time: 0.2371   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:24:04 d2.utils.events]: \u001b[0m eta: 1:19:05  iter: 2019  total_loss: 0.4756  loss_cls: 0.08849  loss_box_reg: 0.1551  loss_mask: 0.1825  loss_rpn_cls: 0.01216  loss_rpn_loc: 0.02928    time: 2.4708  last_time: 3.6467  data_time: 0.2413  last_data_time: 0.2311   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:25:19 d2.utils.events]: \u001b[0m eta: 1:19:26  iter: 2039  total_loss: 0.4845  loss_cls: 0.09479  loss_box_reg: 0.1659  loss_mask: 0.1777  loss_rpn_cls: 0.01193  loss_rpn_loc: 0.02901    time: 2.4834  last_time: 3.8116  data_time: 0.2410  last_data_time: 0.2354   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:26:35 d2.utils.events]: \u001b[0m eta: 1:19:43  iter: 2059  total_loss: 0.4749  loss_cls: 0.09125  loss_box_reg: 0.1675  loss_mask: 0.1819  loss_rpn_cls: 0.01226  loss_rpn_loc: 0.02868    time: 2.4962  last_time: 3.7743  data_time: 0.2388  last_data_time: 0.2390   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:27:51 d2.utils.events]: \u001b[0m eta: 1:22:00  iter: 2079  total_loss: 0.4895  loss_cls: 0.09418  loss_box_reg: 0.1588  loss_mask: 0.1844  loss_rpn_cls: 0.01501  loss_rpn_loc: 0.03023    time: 2.5086  last_time: 3.7311  data_time: 0.2341  last_data_time: 0.2349   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:29:07 d2.utils.events]: \u001b[0m eta: 2:17:54  iter: 2099  total_loss: 0.4566  loss_cls: 0.09222  loss_box_reg: 0.1548  loss_mask: 0.176  loss_rpn_cls: 0.01142  loss_rpn_loc: 0.02662    time: 2.5208  last_time: 3.7594  data_time: 0.2362  last_data_time: 0.2320   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:30:23 d2.utils.events]: \u001b[0m eta: 2:55:54  iter: 2119  total_loss: 0.4777  loss_cls: 0.09241  loss_box_reg: 0.1606  loss_mask: 0.1818  loss_rpn_cls: 0.0123  loss_rpn_loc: 0.02984    time: 2.5329  last_time: 3.6127  data_time: 0.2399  last_data_time: 0.2404   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:31:38 d2.utils.events]: \u001b[0m eta: 2:55:40  iter: 2139  total_loss: 0.4588  loss_cls: 0.0882  loss_box_reg: 0.1521  loss_mask: 0.1805  loss_rpn_cls: 0.01079  loss_rpn_loc: 0.02784    time: 2.5445  last_time: 3.7691  data_time: 0.2370  last_data_time: 0.2274   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:32:55 d2.utils.events]: \u001b[0m eta: 2:55:02  iter: 2159  total_loss: 0.4798  loss_cls: 0.09361  loss_box_reg: 0.156  loss_mask: 0.1773  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.02968    time: 2.5563  last_time: 3.8302  data_time: 0.2379  last_data_time: 0.2350   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:34:12 d2.utils.events]: \u001b[0m eta: 2:54:09  iter: 2179  total_loss: 0.4659  loss_cls: 0.08782  loss_box_reg: 0.1609  loss_mask: 0.1805  loss_rpn_cls: 0.01051  loss_rpn_loc: 0.02858    time: 2.5680  last_time: 3.8447  data_time: 0.2399  last_data_time: 0.2432   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:35:28 d2.utils.events]: \u001b[0m eta: 2:53:08  iter: 2199  total_loss: 0.4785  loss_cls: 0.09225  loss_box_reg: 0.1632  loss_mask: 0.1797  loss_rpn_cls: 0.01156  loss_rpn_loc: 0.02967    time: 2.5793  last_time: 3.7439  data_time: 0.2406  last_data_time: 0.2375   lr: 0.0003  max_mem: 11507M\n",
      "\u001b[32m[04/09 18:36:45 d2.utils.events]: \u001b[0m eta: 2:52:12  iter: 2219  total_loss: 0.4637  loss_cls: 0.0911  loss_box_reg: 0.1521  loss_mask: 0.1807  loss_rpn_cls: 0.01117  loss_rpn_loc: 0.02841    time: 2.5906  last_time: 3.8135  data_time: 0.2612  last_data_time: 0.2640   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:38:02 d2.utils.events]: \u001b[0m eta: 2:51:09  iter: 2239  total_loss: 0.4696  loss_cls: 0.09186  loss_box_reg: 0.1595  loss_mask: 0.1797  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.02791    time: 2.6022  last_time: 3.8368  data_time: 0.2603  last_data_time: 0.2497   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:39:19 d2.utils.events]: \u001b[0m eta: 2:50:06  iter: 2259  total_loss: 0.4491  loss_cls: 0.08439  loss_box_reg: 0.1521  loss_mask: 0.1775  loss_rpn_cls: 0.01159  loss_rpn_loc: 0.0268    time: 2.6131  last_time: 3.7393  data_time: 0.2601  last_data_time: 0.2784   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:40:25 d2.utils.events]: \u001b[0m eta: 2:48:56  iter: 2279  total_loss: 0.4578  loss_cls: 0.08438  loss_box_reg: 0.1538  loss_mask: 0.1794  loss_rpn_cls: 0.011  loss_rpn_loc: 0.02942    time: 2.6193  last_time: 1.6023  data_time: 0.2623  last_data_time: 0.2747   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:41:00 d2.utils.events]: \u001b[0m eta: 2:47:36  iter: 2299  total_loss: 0.4632  loss_cls: 0.0879  loss_box_reg: 0.1549  loss_mask: 0.1782  loss_rpn_cls: 0.01036  loss_rpn_loc: 0.02743    time: 2.6116  last_time: 1.7029  data_time: 0.2910  last_data_time: 0.2871   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:41:35 d2.utils.events]: \u001b[0m eta: 2:46:08  iter: 2319  total_loss: 0.4585  loss_cls: 0.08934  loss_box_reg: 0.1574  loss_mask: 0.1741  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.03    time: 2.6040  last_time: 1.6463  data_time: 0.3013  last_data_time: 0.3062   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:42:08 d2.utils.events]: \u001b[0m eta: 2:44:48  iter: 2339  total_loss: 0.4564  loss_cls: 0.08586  loss_box_reg: 0.156  loss_mask: 0.1759  loss_rpn_cls: 0.01027  loss_rpn_loc: 0.02791    time: 2.5959  last_time: 1.5566  data_time: 0.2943  last_data_time: 0.2664   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:42:41 d2.utils.events]: \u001b[0m eta: 2:43:22  iter: 2359  total_loss: 0.478  loss_cls: 0.09361  loss_box_reg: 0.1566  loss_mask: 0.1767  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.02839    time: 2.5880  last_time: 1.7082  data_time: 0.2953  last_data_time: 0.2942   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:43:15 d2.utils.events]: \u001b[0m eta: 2:41:53  iter: 2379  total_loss: 0.4435  loss_cls: 0.08207  loss_box_reg: 0.1469  loss_mask: 0.1762  loss_rpn_cls: 0.01109  loss_rpn_loc: 0.02706    time: 2.5803  last_time: 1.5662  data_time: 0.2875  last_data_time: 0.2779   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:43:48 d2.utils.events]: \u001b[0m eta: 2:40:25  iter: 2399  total_loss: 0.4527  loss_cls: 0.08611  loss_box_reg: 0.1558  loss_mask: 0.1764  loss_rpn_cls: 0.01093  loss_rpn_loc: 0.02763    time: 2.5725  last_time: 1.6185  data_time: 0.2689  last_data_time: 0.2660   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:44:20 d2.utils.events]: \u001b[0m eta: 2:38:24  iter: 2419  total_loss: 0.4481  loss_cls: 0.08816  loss_box_reg: 0.1513  loss_mask: 0.1743  loss_rpn_cls: 0.01076  loss_rpn_loc: 0.02783    time: 2.5648  last_time: 1.5086  data_time: 0.2616  last_data_time: 0.2594   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:44:52 d2.utils.events]: \u001b[0m eta: 2:35:18  iter: 2439  total_loss: 0.4536  loss_cls: 0.08417  loss_box_reg: 0.1571  loss_mask: 0.1742  loss_rpn_cls: 0.01087  loss_rpn_loc: 0.02796    time: 2.5568  last_time: 2.3287  data_time: 0.2551  last_data_time: 0.2453   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:45:14 d2.utils.events]: \u001b[0m eta: 1:22:31  iter: 2459  total_loss: 0.4551  loss_cls: 0.08594  loss_box_reg: 0.1577  loss_mask: 0.1744  loss_rpn_cls: 0.009447  loss_rpn_loc: 0.0257    time: 2.5449  last_time: 1.0569  data_time: 0.2473  last_data_time: 0.2501   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:45:36 d2.utils.events]: \u001b[0m eta: 1:15:39  iter: 2479  total_loss: 0.4487  loss_cls: 0.08429  loss_box_reg: 0.1545  loss_mask: 0.1724  loss_rpn_cls: 0.01094  loss_rpn_loc: 0.02701    time: 2.5332  last_time: 1.0926  data_time: 0.2484  last_data_time: 0.2379   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:45:58 d2.utils.events]: \u001b[0m eta: 1:11:06  iter: 2499  total_loss: 0.4561  loss_cls: 0.08402  loss_box_reg: 0.1588  loss_mask: 0.1765  loss_rpn_cls: 0.01023  loss_rpn_loc: 0.028    time: 2.5216  last_time: 1.0832  data_time: 0.2428  last_data_time: 0.2445   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:46:19 d2.utils.events]: \u001b[0m eta: 1:09:28  iter: 2519  total_loss: 0.4544  loss_cls: 0.0853  loss_box_reg: 0.1566  loss_mask: 0.1723  loss_rpn_cls: 0.01104  loss_rpn_loc: 0.02822    time: 2.5102  last_time: 1.0684  data_time: 0.2394  last_data_time: 0.2389   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:46:41 d2.utils.events]: \u001b[0m eta: 1:08:26  iter: 2539  total_loss: 0.4484  loss_cls: 0.08594  loss_box_reg: 0.1541  loss_mask: 0.1737  loss_rpn_cls: 0.01052  loss_rpn_loc: 0.02776    time: 2.4989  last_time: 1.0921  data_time: 0.2402  last_data_time: 0.2549   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:47:03 d2.utils.events]: \u001b[0m eta: 1:07:01  iter: 2559  total_loss: 0.4427  loss_cls: 0.08463  loss_box_reg: 0.1437  loss_mask: 0.1746  loss_rpn_cls: 0.01053  loss_rpn_loc: 0.02784    time: 2.4878  last_time: 1.2870  data_time: 0.2411  last_data_time: 0.2375   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:47:24 d2.utils.events]: \u001b[0m eta: 1:05:38  iter: 2579  total_loss: 0.4445  loss_cls: 0.08298  loss_box_reg: 0.1531  loss_mask: 0.1755  loss_rpn_cls: 0.01089  loss_rpn_loc: 0.02875    time: 2.4768  last_time: 1.0860  data_time: 0.2400  last_data_time: 0.2517   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:48:02 d2.utils.events]: \u001b[0m eta: 1:04:48  iter: 2599  total_loss: 0.4432  loss_cls: 0.08439  loss_box_reg: 0.1539  loss_mask: 0.1746  loss_rpn_cls: 0.01006  loss_rpn_loc: 0.02816    time: 2.4725  last_time: 3.7889  data_time: 0.2413  last_data_time: 0.2368   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:49:19 d2.utils.events]: \u001b[0m eta: 1:04:20  iter: 2619  total_loss: 0.4486  loss_cls: 0.08398  loss_box_reg: 0.1493  loss_mask: 0.1711  loss_rpn_cls: 0.009695  loss_rpn_loc: 0.02884    time: 2.4827  last_time: 3.7535  data_time: 0.2396  last_data_time: 0.2456   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:50:35 d2.utils.events]: \u001b[0m eta: 1:04:40  iter: 2639  total_loss: 0.4369  loss_cls: 0.07948  loss_box_reg: 0.1521  loss_mask: 0.1717  loss_rpn_cls: 0.009406  loss_rpn_loc: 0.02597    time: 2.4927  last_time: 3.8174  data_time: 0.2440  last_data_time: 0.2600   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:51:41 d2.utils.events]: \u001b[0m eta: 1:04:26  iter: 2659  total_loss: 0.4317  loss_cls: 0.08039  loss_box_reg: 0.15  loss_mask: 0.171  loss_rpn_cls: 0.01031  loss_rpn_loc: 0.02567    time: 2.4989  last_time: 1.0724  data_time: 0.2508  last_data_time: 0.2603   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:52:03 d2.utils.events]: \u001b[0m eta: 1:03:49  iter: 2679  total_loss: 0.4365  loss_cls: 0.08083  loss_box_reg: 0.1494  loss_mask: 0.1711  loss_rpn_cls: 0.009822  loss_rpn_loc: 0.02711    time: 2.4883  last_time: 1.0893  data_time: 0.2402  last_data_time: 0.2307   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:52:24 d2.utils.events]: \u001b[0m eta: 1:03:09  iter: 2699  total_loss: 0.4566  loss_cls: 0.08568  loss_box_reg: 0.1555  loss_mask: 0.1715  loss_rpn_cls: 0.009368  loss_rpn_loc: 0.02785    time: 2.4779  last_time: 1.3187  data_time: 0.2410  last_data_time: 0.2476   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:52:46 d2.utils.events]: \u001b[0m eta: 1:02:33  iter: 2719  total_loss: 0.4217  loss_cls: 0.07538  loss_box_reg: 0.147  loss_mask: 0.1668  loss_rpn_cls: 0.009715  loss_rpn_loc: 0.02754    time: 2.4676  last_time: 1.0642  data_time: 0.2430  last_data_time: 0.2457   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:53:08 d2.utils.events]: \u001b[0m eta: 1:01:43  iter: 2739  total_loss: 0.448  loss_cls: 0.08234  loss_box_reg: 0.16  loss_mask: 0.1696  loss_rpn_cls: 0.009688  loss_rpn_loc: 0.02849    time: 2.4575  last_time: 1.0503  data_time: 0.2396  last_data_time: 0.2363   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:53:29 d2.utils.events]: \u001b[0m eta: 1:00:44  iter: 2759  total_loss: 0.4472  loss_cls: 0.08017  loss_box_reg: 0.1478  loss_mask: 0.1717  loss_rpn_cls: 0.009998  loss_rpn_loc: 0.02756    time: 2.4475  last_time: 1.0720  data_time: 0.2399  last_data_time: 0.2469   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:53:51 d2.utils.events]: \u001b[0m eta: 0:59:57  iter: 2779  total_loss: 0.4433  loss_cls: 0.08043  loss_box_reg: 0.1513  loss_mask: 0.1661  loss_rpn_cls: 0.009272  loss_rpn_loc: 0.02643    time: 2.4377  last_time: 1.0233  data_time: 0.2443  last_data_time: 0.2360   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:54:13 d2.utils.events]: \u001b[0m eta: 0:59:25  iter: 2799  total_loss: 0.4373  loss_cls: 0.07883  loss_box_reg: 0.1457  loss_mask: 0.1708  loss_rpn_cls: 0.008439  loss_rpn_loc: 0.02716    time: 2.4280  last_time: 1.0661  data_time: 0.2425  last_data_time: 0.2528   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:54:34 d2.utils.events]: \u001b[0m eta: 0:58:52  iter: 2819  total_loss: 0.4446  loss_cls: 0.07943  loss_box_reg: 0.1502  loss_mask: 0.1702  loss_rpn_cls: 0.009206  loss_rpn_loc: 0.02742    time: 2.4184  last_time: 1.3059  data_time: 0.2384  last_data_time: 0.2558   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:54:55 d2.utils.events]: \u001b[0m eta: 0:58:20  iter: 2839  total_loss: 0.4184  loss_cls: 0.07695  loss_box_reg: 0.1424  loss_mask: 0.1697  loss_rpn_cls: 0.008382  loss_rpn_loc: 0.02431    time: 2.4089  last_time: 1.0570  data_time: 0.2377  last_data_time: 0.2407   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:55:17 d2.utils.events]: \u001b[0m eta: 0:57:47  iter: 2859  total_loss: 0.4369  loss_cls: 0.07799  loss_box_reg: 0.1512  loss_mask: 0.171  loss_rpn_cls: 0.008643  loss_rpn_loc: 0.02582    time: 2.3996  last_time: 1.0802  data_time: 0.2397  last_data_time: 0.2362   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:55:39 d2.utils.events]: \u001b[0m eta: 0:57:15  iter: 2879  total_loss: 0.4334  loss_cls: 0.07906  loss_box_reg: 0.15  loss_mask: 0.1654  loss_rpn_cls: 0.01034  loss_rpn_loc: 0.0259    time: 2.3905  last_time: 1.0870  data_time: 0.2398  last_data_time: 0.2507   lr: 0.0003  max_mem: 11633M\n",
      "\u001b[32m[04/09 18:56:00 d2.utils.events]: \u001b[0m eta: 0:56:43  iter: 2899  total_loss: 0.4272  loss_cls: 0.08107  loss_box_reg: 0.149  loss_mask: 0.1708  loss_rpn_cls: 0.007263  loss_rpn_loc: 0.02457    time: 2.3814  last_time: 1.0964  data_time: 0.2399  last_data_time: 0.2437   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:56:22 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 2919  total_loss: 0.4416  loss_cls: 0.08054  loss_box_reg: 0.1524  loss_mask: 0.1686  loss_rpn_cls: 0.009184  loss_rpn_loc: 0.02773    time: 2.3726  last_time: 1.0521  data_time: 0.2426  last_data_time: 0.2453   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:56:44 d2.utils.events]: \u001b[0m eta: 0:55:36  iter: 2939  total_loss: 0.4275  loss_cls: 0.07885  loss_box_reg: 0.1497  loss_mask: 0.1665  loss_rpn_cls: 0.007256  loss_rpn_loc: 0.02413    time: 2.3638  last_time: 1.0562  data_time: 0.2416  last_data_time: 0.2443   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:57:05 d2.utils.events]: \u001b[0m eta: 0:54:28  iter: 2959  total_loss: 0.4268  loss_cls: 0.07974  loss_box_reg: 0.1445  loss_mask: 0.1687  loss_rpn_cls: 0.009125  loss_rpn_loc: 0.02611    time: 2.3551  last_time: 1.0472  data_time: 0.2360  last_data_time: 0.2360   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:57:27 d2.utils.events]: \u001b[0m eta: 0:52:50  iter: 2979  total_loss: 0.4366  loss_cls: 0.07924  loss_box_reg: 0.1479  loss_mask: 0.1677  loss_rpn_cls: 0.008834  loss_rpn_loc: 0.02657    time: 2.3465  last_time: 1.0953  data_time: 0.2337  last_data_time: 0.2383   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:57:49 d2.utils.events]: \u001b[0m eta: 0:47:32  iter: 2999  total_loss: 0.4267  loss_cls: 0.07783  loss_box_reg: 0.1493  loss_mask: 0.1635  loss_rpn_cls: 0.009278  loss_rpn_loc: 0.02562    time: 2.3382  last_time: 1.0709  data_time: 0.2376  last_data_time: 0.2289   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:58:11 d2.utils.events]: \u001b[0m eta: 0:42:57  iter: 3019  total_loss: 0.4205  loss_cls: 0.07215  loss_box_reg: 0.1445  loss_mask: 0.1671  loss_rpn_cls: 0.008843  loss_rpn_loc: 0.0269    time: 2.3299  last_time: 1.0665  data_time: 0.2399  last_data_time: 0.2388   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:58:33 d2.utils.events]: \u001b[0m eta: 0:41:25  iter: 3039  total_loss: 0.4132  loss_cls: 0.07423  loss_box_reg: 0.1426  loss_mask: 0.1683  loss_rpn_cls: 0.008054  loss_rpn_loc: 0.02516    time: 2.3217  last_time: 1.1112  data_time: 0.2442  last_data_time: 0.2493   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:58:55 d2.utils.events]: \u001b[0m eta: 0:36:16  iter: 3059  total_loss: 0.4256  loss_cls: 0.07667  loss_box_reg: 0.1506  loss_mask: 0.1644  loss_rpn_cls: 0.009207  loss_rpn_loc: 0.02846    time: 2.3137  last_time: 1.4100  data_time: 0.2398  last_data_time: 0.2453   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:59:16 d2.utils.events]: \u001b[0m eta: 0:35:13  iter: 3079  total_loss: 0.4358  loss_cls: 0.07715  loss_box_reg: 0.1465  loss_mask: 0.1642  loss_rpn_cls: 0.008434  loss_rpn_loc: 0.02822    time: 2.3057  last_time: 1.0542  data_time: 0.2386  last_data_time: 0.2341   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 18:59:38 d2.utils.events]: \u001b[0m eta: 0:34:41  iter: 3099  total_loss: 0.4315  loss_cls: 0.07725  loss_box_reg: 0.1513  loss_mask: 0.1644  loss_rpn_cls: 0.008952  loss_rpn_loc: 0.02758    time: 2.2979  last_time: 1.0624  data_time: 0.2400  last_data_time: 0.2320   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:00:00 d2.utils.events]: \u001b[0m eta: 0:34:09  iter: 3119  total_loss: 0.4143  loss_cls: 0.07256  loss_box_reg: 0.1439  loss_mask: 0.1656  loss_rpn_cls: 0.007903  loss_rpn_loc: 0.02627    time: 2.2901  last_time: 1.0605  data_time: 0.2421  last_data_time: 0.2468   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:00:22 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 3139  total_loss: 0.405  loss_cls: 0.07223  loss_box_reg: 0.1395  loss_mask: 0.1646  loss_rpn_cls: 0.00768  loss_rpn_loc: 0.02529    time: 2.2824  last_time: 1.0233  data_time: 0.2349  last_data_time: 0.2286   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:00:43 d2.utils.events]: \u001b[0m eta: 0:33:13  iter: 3159  total_loss: 0.4156  loss_cls: 0.07233  loss_box_reg: 0.1462  loss_mask: 0.1687  loss_rpn_cls: 0.007166  loss_rpn_loc: 0.02652    time: 2.2748  last_time: 1.3333  data_time: 0.2361  last_data_time: 0.2331   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:01:05 d2.utils.events]: \u001b[0m eta: 0:32:45  iter: 3179  total_loss: 0.4204  loss_cls: 0.07696  loss_box_reg: 0.1491  loss_mask: 0.1638  loss_rpn_cls: 0.006861  loss_rpn_loc: 0.02638    time: 2.2672  last_time: 1.0685  data_time: 0.2329  last_data_time: 0.2305   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:01:27 d2.utils.events]: \u001b[0m eta: 0:32:20  iter: 3199  total_loss: 0.4242  loss_cls: 0.0729  loss_box_reg: 0.1452  loss_mask: 0.1655  loss_rpn_cls: 0.008068  loss_rpn_loc: 0.0286    time: 2.2599  last_time: 1.0519  data_time: 0.2383  last_data_time: 0.2380   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:01:48 d2.utils.events]: \u001b[0m eta: 0:31:57  iter: 3219  total_loss: 0.4294  loss_cls: 0.07628  loss_box_reg: 0.1551  loss_mask: 0.1635  loss_rpn_cls: 0.007869  loss_rpn_loc: 0.0271    time: 2.2526  last_time: 1.0719  data_time: 0.2368  last_data_time: 0.2383   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:02:10 d2.utils.events]: \u001b[0m eta: 0:31:33  iter: 3239  total_loss: 0.412  loss_cls: 0.07142  loss_box_reg: 0.138  loss_mask: 0.1639  loss_rpn_cls: 0.008415  loss_rpn_loc: 0.02575    time: 2.2454  last_time: 1.0506  data_time: 0.2393  last_data_time: 0.2417   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:02:32 d2.utils.events]: \u001b[0m eta: 0:31:10  iter: 3259  total_loss: 0.4219  loss_cls: 0.07639  loss_box_reg: 0.1431  loss_mask: 0.1634  loss_rpn_cls: 0.00792  loss_rpn_loc: 0.0304    time: 2.2383  last_time: 1.0459  data_time: 0.2471  last_data_time: 0.2412   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:02:54 d2.utils.events]: \u001b[0m eta: 0:30:46  iter: 3279  total_loss: 0.4219  loss_cls: 0.07368  loss_box_reg: 0.1483  loss_mask: 0.1634  loss_rpn_cls: 0.007914  loss_rpn_loc: 0.02684    time: 2.2315  last_time: 1.6963  data_time: 0.2446  last_data_time: 0.2684   lr: 0.0003  max_mem: 11656M\n",
      "\u001b[32m[04/09 19:03:16 d2.utils.events]: \u001b[0m eta: 0:30:25  iter: 3299  total_loss: 0.418  loss_cls: 0.07366  loss_box_reg: 0.1472  loss_mask: 0.1649  loss_rpn_cls: 0.008172  loss_rpn_loc: 0.02586    time: 2.2247  last_time: 1.0676  data_time: 0.2496  last_data_time: 0.2369   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:03:40 d2.utils.events]: \u001b[0m eta: 0:30:03  iter: 3319  total_loss: 0.4044  loss_cls: 0.07074  loss_box_reg: 0.1434  loss_mask: 0.1631  loss_rpn_cls: 0.007747  loss_rpn_loc: 0.02455    time: 2.2182  last_time: 1.1087  data_time: 0.2475  last_data_time: 0.2473   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:04:02 d2.utils.events]: \u001b[0m eta: 0:29:41  iter: 3339  total_loss: 0.4208  loss_cls: 0.07474  loss_box_reg: 0.1499  loss_mask: 0.1631  loss_rpn_cls: 0.008369  loss_rpn_loc: 0.02518    time: 2.2118  last_time: 1.0600  data_time: 0.2575  last_data_time: 0.2498   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:04:25 d2.utils.events]: \u001b[0m eta: 0:29:18  iter: 3359  total_loss: 0.3966  loss_cls: 0.07023  loss_box_reg: 0.1405  loss_mask: 0.1604  loss_rpn_cls: 0.007014  loss_rpn_loc: 0.02593    time: 2.2053  last_time: 1.1133  data_time: 0.2529  last_data_time: 0.2420   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:04:47 d2.utils.events]: \u001b[0m eta: 0:28:56  iter: 3379  total_loss: 0.4116  loss_cls: 0.06923  loss_box_reg: 0.1458  loss_mask: 0.1626  loss_rpn_cls: 0.007625  loss_rpn_loc: 0.02651    time: 2.1988  last_time: 1.0797  data_time: 0.2529  last_data_time: 0.2453   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:05:10 d2.utils.events]: \u001b[0m eta: 0:28:35  iter: 3399  total_loss: 0.4189  loss_cls: 0.07468  loss_box_reg: 0.1522  loss_mask: 0.1631  loss_rpn_cls: 0.00777  loss_rpn_loc: 0.02482    time: 2.1924  last_time: 1.4494  data_time: 0.2542  last_data_time: 0.2549   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:05:31 d2.utils.events]: \u001b[0m eta: 0:28:13  iter: 3419  total_loss: 0.4162  loss_cls: 0.07012  loss_box_reg: 0.1477  loss_mask: 0.1629  loss_rpn_cls: 0.008748  loss_rpn_loc: 0.02625    time: 2.1860  last_time: 1.0914  data_time: 0.2474  last_data_time: 0.2456   lr: 0.0003  max_mem: 11693M\n",
      "\u001b[32m[04/09 19:05:54 d2.utils.events]: \u001b[0m eta: 0:27:51  iter: 3439  total_loss: 0.4024  loss_cls: 0.07105  loss_box_reg: 0.1365  loss_mask: 0.1622  loss_rpn_cls: 0.007434  loss_rpn_loc: 0.02383    time: 2.1797  last_time: 1.0568  data_time: 0.2459  last_data_time: 0.2457   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:06:16 d2.utils.events]: \u001b[0m eta: 0:27:29  iter: 3459  total_loss: 0.3974  loss_cls: 0.06976  loss_box_reg: 0.1417  loss_mask: 0.1644  loss_rpn_cls: 0.008079  loss_rpn_loc: 0.02469    time: 2.1735  last_time: 1.0809  data_time: 0.2473  last_data_time: 0.2543   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:06:38 d2.utils.events]: \u001b[0m eta: 0:27:08  iter: 3479  total_loss: 0.4017  loss_cls: 0.07078  loss_box_reg: 0.1423  loss_mask: 0.1598  loss_rpn_cls: 0.00753  loss_rpn_loc: 0.02617    time: 2.1674  last_time: 1.0735  data_time: 0.2502  last_data_time: 0.2490   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:07:00 d2.utils.events]: \u001b[0m eta: 0:26:47  iter: 3499  total_loss: 0.4056  loss_cls: 0.07073  loss_box_reg: 0.1399  loss_mask: 0.1614  loss_rpn_cls: 0.007033  loss_rpn_loc: 0.02504    time: 2.1613  last_time: 1.0768  data_time: 0.2522  last_data_time: 0.2582   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:07:22 d2.utils.events]: \u001b[0m eta: 0:26:27  iter: 3519  total_loss: 0.4129  loss_cls: 0.07368  loss_box_reg: 0.1429  loss_mask: 0.1596  loss_rpn_cls: 0.006833  loss_rpn_loc: 0.02565    time: 2.1553  last_time: 1.1164  data_time: 0.2488  last_data_time: 0.2449   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:07:44 d2.utils.events]: \u001b[0m eta: 0:26:05  iter: 3539  total_loss: 0.3929  loss_cls: 0.068  loss_box_reg: 0.1359  loss_mask: 0.1601  loss_rpn_cls: 0.006522  loss_rpn_loc: 0.02416    time: 2.1492  last_time: 1.1112  data_time: 0.2484  last_data_time: 0.2666   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:08:06 d2.utils.events]: \u001b[0m eta: 0:25:45  iter: 3559  total_loss: 0.4098  loss_cls: 0.06932  loss_box_reg: 0.1458  loss_mask: 0.1605  loss_rpn_cls: 0.006521  loss_rpn_loc: 0.02607    time: 2.1434  last_time: 1.0731  data_time: 0.2569  last_data_time: 0.2538   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:08:28 d2.utils.events]: \u001b[0m eta: 0:25:24  iter: 3579  total_loss: 0.3979  loss_cls: 0.06688  loss_box_reg: 0.139  loss_mask: 0.1616  loss_rpn_cls: 0.006979  loss_rpn_loc: 0.02432    time: 2.1376  last_time: 1.0784  data_time: 0.2486  last_data_time: 0.2348   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:08:51 d2.utils.events]: \u001b[0m eta: 0:25:03  iter: 3599  total_loss: 0.3991  loss_cls: 0.06854  loss_box_reg: 0.1403  loss_mask: 0.1594  loss_rpn_cls: 0.006269  loss_rpn_loc: 0.02694    time: 2.1319  last_time: 1.0643  data_time: 0.2508  last_data_time: 0.2444   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:09:13 d2.utils.events]: \u001b[0m eta: 0:24:40  iter: 3619  total_loss: 0.4004  loss_cls: 0.06781  loss_box_reg: 0.1413  loss_mask: 0.1588  loss_rpn_cls: 0.00733  loss_rpn_loc: 0.02403    time: 2.1262  last_time: 1.0993  data_time: 0.2447  last_data_time: 0.2396   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:09:35 d2.utils.events]: \u001b[0m eta: 0:24:18  iter: 3639  total_loss: 0.412  loss_cls: 0.07006  loss_box_reg: 0.1458  loss_mask: 0.1588  loss_rpn_cls: 0.007192  loss_rpn_loc: 0.02722    time: 2.1206  last_time: 1.0839  data_time: 0.2398  last_data_time: 0.2460   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:09:57 d2.utils.events]: \u001b[0m eta: 0:23:56  iter: 3659  total_loss: 0.4037  loss_cls: 0.06503  loss_box_reg: 0.1456  loss_mask: 0.1589  loss_rpn_cls: 0.006485  loss_rpn_loc: 0.02438    time: 2.1150  last_time: 1.4323  data_time: 0.2411  last_data_time: 0.2401   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:10:19 d2.utils.events]: \u001b[0m eta: 0:23:36  iter: 3679  total_loss: 0.399  loss_cls: 0.06752  loss_box_reg: 0.1412  loss_mask: 0.1578  loss_rpn_cls: 0.006142  loss_rpn_loc: 0.02427    time: 2.1094  last_time: 1.0487  data_time: 0.2462  last_data_time: 0.2461   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:10:40 d2.utils.events]: \u001b[0m eta: 0:23:14  iter: 3699  total_loss: 0.4037  loss_cls: 0.07008  loss_box_reg: 0.1415  loss_mask: 0.1569  loss_rpn_cls: 0.007395  loss_rpn_loc: 0.02592    time: 2.1040  last_time: 1.0581  data_time: 0.2364  last_data_time: 0.2330   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:11:02 d2.utils.events]: \u001b[0m eta: 0:22:53  iter: 3719  total_loss: 0.3932  loss_cls: 0.06909  loss_box_reg: 0.1379  loss_mask: 0.1597  loss_rpn_cls: 0.006463  loss_rpn_loc: 0.02368    time: 2.0985  last_time: 1.0517  data_time: 0.2352  last_data_time: 0.2368   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:11:24 d2.utils.events]: \u001b[0m eta: 0:22:31  iter: 3739  total_loss: 0.3907  loss_cls: 0.06386  loss_box_reg: 0.1351  loss_mask: 0.1587  loss_rpn_cls: 0.007629  loss_rpn_loc: 0.02447    time: 2.0931  last_time: 1.0414  data_time: 0.2403  last_data_time: 0.2300   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:11:46 d2.utils.events]: \u001b[0m eta: 0:22:10  iter: 3759  total_loss: 0.4002  loss_cls: 0.06841  loss_box_reg: 0.1357  loss_mask: 0.1593  loss_rpn_cls: 0.006362  loss_rpn_loc: 0.0259    time: 2.0878  last_time: 1.0892  data_time: 0.2421  last_data_time: 0.2450   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:12:08 d2.utils.events]: \u001b[0m eta: 0:21:49  iter: 3779  total_loss: 0.4029  loss_cls: 0.0698  loss_box_reg: 0.1431  loss_mask: 0.1574  loss_rpn_cls: 0.007035  loss_rpn_loc: 0.0254    time: 2.0826  last_time: 1.0642  data_time: 0.2422  last_data_time: 0.2400   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:12:30 d2.utils.events]: \u001b[0m eta: 0:21:29  iter: 3799  total_loss: 0.3999  loss_cls: 0.06764  loss_box_reg: 0.1418  loss_mask: 0.1552  loss_rpn_cls: 0.006293  loss_rpn_loc: 0.02565    time: 2.0774  last_time: 1.0771  data_time: 0.2417  last_data_time: 0.2338   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:12:52 d2.utils.events]: \u001b[0m eta: 0:21:08  iter: 3819  total_loss: 0.3914  loss_cls: 0.06661  loss_box_reg: 0.1386  loss_mask: 0.1565  loss_rpn_cls: 0.006982  loss_rpn_loc: 0.02455    time: 2.0722  last_time: 1.0768  data_time: 0.2406  last_data_time: 0.2389   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:13:14 d2.utils.events]: \u001b[0m eta: 0:20:47  iter: 3839  total_loss: 0.4028  loss_cls: 0.06569  loss_box_reg: 0.141  loss_mask: 0.158  loss_rpn_cls: 0.006517  loss_rpn_loc: 0.02412    time: 2.0671  last_time: 1.0825  data_time: 0.2421  last_data_time: 0.2393   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:13:36 d2.utils.events]: \u001b[0m eta: 0:20:25  iter: 3859  total_loss: 0.3952  loss_cls: 0.06686  loss_box_reg: 0.1421  loss_mask: 0.1572  loss_rpn_cls: 0.007205  loss_rpn_loc: 0.02461    time: 2.0621  last_time: 1.0772  data_time: 0.2369  last_data_time: 0.2410   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:13:58 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 3879  total_loss: 0.3915  loss_cls: 0.06548  loss_box_reg: 0.137  loss_mask: 0.1563  loss_rpn_cls: 0.006614  loss_rpn_loc: 0.02431    time: 2.0571  last_time: 1.0838  data_time: 0.2354  last_data_time: 0.2424   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:14:19 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 3899  total_loss: 0.3833  loss_cls: 0.06346  loss_box_reg: 0.1357  loss_mask: 0.1542  loss_rpn_cls: 0.007147  loss_rpn_loc: 0.02313    time: 2.0521  last_time: 1.0947  data_time: 0.2360  last_data_time: 0.2387   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:14:41 d2.utils.events]: \u001b[0m eta: 0:19:21  iter: 3919  total_loss: 0.3886  loss_cls: 0.0651  loss_box_reg: 0.136  loss_mask: 0.1554  loss_rpn_cls: 0.007036  loss_rpn_loc: 0.02671    time: 2.0472  last_time: 1.0549  data_time: 0.2383  last_data_time: 0.2338   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:15:03 d2.utils.events]: \u001b[0m eta: 0:19:00  iter: 3939  total_loss: 0.3948  loss_cls: 0.0655  loss_box_reg: 0.138  loss_mask: 0.1582  loss_rpn_cls: 0.006499  loss_rpn_loc: 0.0263    time: 2.0424  last_time: 1.1029  data_time: 0.2364  last_data_time: 0.2339   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:15:25 d2.utils.events]: \u001b[0m eta: 0:18:38  iter: 3959  total_loss: 0.3899  loss_cls: 0.06466  loss_box_reg: 0.136  loss_mask: 0.1542  loss_rpn_cls: 0.005755  loss_rpn_loc: 0.02397    time: 2.0375  last_time: 1.0680  data_time: 0.2356  last_data_time: 0.2335   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:15:47 d2.utils.events]: \u001b[0m eta: 0:18:17  iter: 3979  total_loss: 0.4001  loss_cls: 0.06742  loss_box_reg: 0.1454  loss_mask: 0.156  loss_rpn_cls: 0.005735  loss_rpn_loc: 0.02494    time: 2.0328  last_time: 1.0654  data_time: 0.2398  last_data_time: 0.2348   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:16:09 d2.utils.events]: \u001b[0m eta: 0:17:56  iter: 3999  total_loss: 0.393  loss_cls: 0.06511  loss_box_reg: 0.1363  loss_mask: 0.1555  loss_rpn_cls: 0.00631  loss_rpn_loc: 0.02488    time: 2.0281  last_time: 1.0541  data_time: 0.2368  last_data_time: 0.2363   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:16:31 d2.utils.events]: \u001b[0m eta: 0:17:35  iter: 4019  total_loss: 0.3809  loss_cls: 0.06293  loss_box_reg: 0.1355  loss_mask: 0.1539  loss_rpn_cls: 0.006463  loss_rpn_loc: 0.02459    time: 2.0235  last_time: 1.0693  data_time: 0.2408  last_data_time: 0.2332   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:16:53 d2.utils.events]: \u001b[0m eta: 0:17:13  iter: 4039  total_loss: 0.3862  loss_cls: 0.06365  loss_box_reg: 0.1402  loss_mask: 0.1547  loss_rpn_cls: 0.005585  loss_rpn_loc: 0.02515    time: 2.0190  last_time: 1.3298  data_time: 0.2448  last_data_time: 0.2406   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:17:15 d2.utils.events]: \u001b[0m eta: 0:16:52  iter: 4059  total_loss: 0.3815  loss_cls: 0.06127  loss_box_reg: 0.1357  loss_mask: 0.1541  loss_rpn_cls: 0.005721  loss_rpn_loc: 0.02238    time: 2.0144  last_time: 1.0874  data_time: 0.2411  last_data_time: 0.2497   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:17:36 d2.utils.events]: \u001b[0m eta: 0:16:30  iter: 4079  total_loss: 0.3929  loss_cls: 0.06786  loss_box_reg: 0.1418  loss_mask: 0.1537  loss_rpn_cls: 0.00687  loss_rpn_loc: 0.02465    time: 2.0098  last_time: 1.0781  data_time: 0.2352  last_data_time: 0.2351   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:17:58 d2.utils.events]: \u001b[0m eta: 0:16:09  iter: 4099  total_loss: 0.3783  loss_cls: 0.06372  loss_box_reg: 0.1347  loss_mask: 0.1537  loss_rpn_cls: 0.006336  loss_rpn_loc: 0.02477    time: 2.0053  last_time: 1.0743  data_time: 0.2333  last_data_time: 0.2388   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:18:20 d2.utils.events]: \u001b[0m eta: 0:15:47  iter: 4119  total_loss: 0.3765  loss_cls: 0.0596  loss_box_reg: 0.1332  loss_mask: 0.1542  loss_rpn_cls: 0.006063  loss_rpn_loc: 0.023    time: 2.0009  last_time: 1.0566  data_time: 0.2351  last_data_time: 0.2398   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:18:42 d2.utils.events]: \u001b[0m eta: 0:15:26  iter: 4139  total_loss: 0.3838  loss_cls: 0.06074  loss_box_reg: 0.1356  loss_mask: 0.155  loss_rpn_cls: 0.006202  loss_rpn_loc: 0.02514    time: 1.9965  last_time: 1.0324  data_time: 0.2351  last_data_time: 0.2293   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:19:04 d2.utils.events]: \u001b[0m eta: 0:15:04  iter: 4159  total_loss: 0.3975  loss_cls: 0.06709  loss_box_reg: 0.1431  loss_mask: 0.1559  loss_rpn_cls: 0.006655  loss_rpn_loc: 0.02449    time: 1.9921  last_time: 1.0731  data_time: 0.2336  last_data_time: 0.2367   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:19:26 d2.utils.events]: \u001b[0m eta: 0:14:43  iter: 4179  total_loss: 0.3855  loss_cls: 0.06359  loss_box_reg: 0.132  loss_mask: 0.1517  loss_rpn_cls: 0.006763  loss_rpn_loc: 0.02352    time: 1.9878  last_time: 1.3237  data_time: 0.2373  last_data_time: 0.2348   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:19:47 d2.utils.events]: \u001b[0m eta: 0:14:21  iter: 4199  total_loss: 0.3964  loss_cls: 0.06361  loss_box_reg: 0.1404  loss_mask: 0.1538  loss_rpn_cls: 0.005981  loss_rpn_loc: 0.02669    time: 1.9835  last_time: 1.0987  data_time: 0.2369  last_data_time: 0.2435   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:20:09 d2.utils.events]: \u001b[0m eta: 0:14:00  iter: 4219  total_loss: 0.396  loss_cls: 0.06342  loss_box_reg: 0.1382  loss_mask: 0.1534  loss_rpn_cls: 0.0066  loss_rpn_loc: 0.02494    time: 1.9793  last_time: 1.1034  data_time: 0.2359  last_data_time: 0.2393   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:20:31 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 4239  total_loss: 0.3725  loss_cls: 0.06181  loss_box_reg: 0.1337  loss_mask: 0.15  loss_rpn_cls: 0.006275  loss_rpn_loc: 0.026    time: 1.9751  last_time: 1.0675  data_time: 0.2356  last_data_time: 0.2295   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:20:53 d2.utils.events]: \u001b[0m eta: 0:13:17  iter: 4259  total_loss: 0.3835  loss_cls: 0.0645  loss_box_reg: 0.1389  loss_mask: 0.153  loss_rpn_cls: 0.005872  loss_rpn_loc: 0.02488    time: 1.9710  last_time: 1.0390  data_time: 0.2390  last_data_time: 0.2283   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:21:15 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 4279  total_loss: 0.3729  loss_cls: 0.061  loss_box_reg: 0.1322  loss_mask: 0.152  loss_rpn_cls: 0.00646  loss_rpn_loc: 0.02646    time: 1.9670  last_time: 1.0433  data_time: 0.2519  last_data_time: 0.2403   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:21:37 d2.utils.events]: \u001b[0m eta: 0:12:33  iter: 4299  total_loss: 0.3811  loss_cls: 0.06149  loss_box_reg: 0.1392  loss_mask: 0.1507  loss_rpn_cls: 0.005671  loss_rpn_loc: 0.02453    time: 1.9630  last_time: 1.0649  data_time: 0.2411  last_data_time: 0.2390   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:21:59 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 4319  total_loss: 0.387  loss_cls: 0.06343  loss_box_reg: 0.1382  loss_mask: 0.1516  loss_rpn_cls: 0.005928  loss_rpn_loc: 0.02479    time: 1.9590  last_time: 1.3407  data_time: 0.2411  last_data_time: 0.2390   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:22:21 d2.utils.events]: \u001b[0m eta: 0:11:50  iter: 4339  total_loss: 0.373  loss_cls: 0.06063  loss_box_reg: 0.134  loss_mask: 0.1511  loss_rpn_cls: 0.00507  loss_rpn_loc: 0.02308    time: 1.9550  last_time: 1.0769  data_time: 0.2431  last_data_time: 0.2436   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:22:44 d2.utils.events]: \u001b[0m eta: 0:11:28  iter: 4359  total_loss: 0.3833  loss_cls: 0.0583  loss_box_reg: 0.1317  loss_mask: 0.1532  loss_rpn_cls: 0.005367  loss_rpn_loc: 0.02251    time: 1.9511  last_time: 1.0664  data_time: 0.2357  last_data_time: 0.2375   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:23:06 d2.utils.events]: \u001b[0m eta: 0:11:07  iter: 4379  total_loss: 0.3853  loss_cls: 0.06205  loss_box_reg: 0.1372  loss_mask: 0.1519  loss_rpn_cls: 0.006203  loss_rpn_loc: 0.02417    time: 1.9472  last_time: 1.1092  data_time: 0.2400  last_data_time: 0.2415   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:23:28 d2.utils.events]: \u001b[0m eta: 0:10:45  iter: 4399  total_loss: 0.3735  loss_cls: 0.05768  loss_box_reg: 0.1323  loss_mask: 0.152  loss_rpn_cls: 0.005924  loss_rpn_loc: 0.02437    time: 1.9434  last_time: 1.0564  data_time: 0.2334  last_data_time: 0.2287   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:23:50 d2.utils.events]: \u001b[0m eta: 0:10:23  iter: 4419  total_loss: 0.3731  loss_cls: 0.05772  loss_box_reg: 0.1297  loss_mask: 0.1505  loss_rpn_cls: 0.005894  loss_rpn_loc: 0.02314    time: 1.9395  last_time: 1.3920  data_time: 0.2400  last_data_time: 0.2473   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:24:11 d2.utils.events]: \u001b[0m eta: 0:10:02  iter: 4439  total_loss: 0.369  loss_cls: 0.05822  loss_box_reg: 0.132  loss_mask: 0.1485  loss_rpn_cls: 0.005953  loss_rpn_loc: 0.02324    time: 1.9357  last_time: 1.0577  data_time: 0.2363  last_data_time: 0.2336   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:24:33 d2.utils.events]: \u001b[0m eta: 0:09:40  iter: 4459  total_loss: 0.3794  loss_cls: 0.06068  loss_box_reg: 0.1342  loss_mask: 0.1524  loss_rpn_cls: 0.005681  loss_rpn_loc: 0.023    time: 1.9319  last_time: 1.0540  data_time: 0.2349  last_data_time: 0.2325   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:24:55 d2.utils.events]: \u001b[0m eta: 0:09:18  iter: 4479  total_loss: 0.3807  loss_cls: 0.06097  loss_box_reg: 0.1343  loss_mask: 0.1507  loss_rpn_cls: 0.005526  loss_rpn_loc: 0.0228    time: 1.9281  last_time: 1.0717  data_time: 0.2341  last_data_time: 0.2279   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:25:17 d2.utils.events]: \u001b[0m eta: 0:08:57  iter: 4499  total_loss: 0.3727  loss_cls: 0.05633  loss_box_reg: 0.1339  loss_mask: 0.1511  loss_rpn_cls: 0.00497  loss_rpn_loc: 0.0235    time: 1.9244  last_time: 1.0939  data_time: 0.2371  last_data_time: 0.2407   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:25:39 d2.utils.events]: \u001b[0m eta: 0:08:35  iter: 4519  total_loss: 0.3797  loss_cls: 0.06129  loss_box_reg: 0.1357  loss_mask: 0.1538  loss_rpn_cls: 0.005723  loss_rpn_loc: 0.02531    time: 1.9208  last_time: 1.0739  data_time: 0.2367  last_data_time: 0.2319   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:26:01 d2.utils.events]: \u001b[0m eta: 0:08:14  iter: 4539  total_loss: 0.3634  loss_cls: 0.05689  loss_box_reg: 0.1308  loss_mask: 0.148  loss_rpn_cls: 0.005571  loss_rpn_loc: 0.02391    time: 1.9171  last_time: 1.3213  data_time: 0.2381  last_data_time: 0.2401   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:26:23 d2.utils.events]: \u001b[0m eta: 0:07:52  iter: 4559  total_loss: 0.3734  loss_cls: 0.05626  loss_box_reg: 0.1298  loss_mask: 0.1497  loss_rpn_cls: 0.004983  loss_rpn_loc: 0.02391    time: 1.9136  last_time: 1.0893  data_time: 0.2427  last_data_time: 0.2451   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:26:45 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 4579  total_loss: 0.3744  loss_cls: 0.0586  loss_box_reg: 0.1324  loss_mask: 0.1503  loss_rpn_cls: 0.0062  loss_rpn_loc: 0.02506    time: 1.9101  last_time: 1.0786  data_time: 0.2337  last_data_time: 0.2345   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:27:08 d2.utils.events]: \u001b[0m eta: 0:07:09  iter: 4599  total_loss: 0.3612  loss_cls: 0.05594  loss_box_reg: 0.1313  loss_mask: 0.1476  loss_rpn_cls: 0.005183  loss_rpn_loc: 0.02231    time: 1.9066  last_time: 1.0595  data_time: 0.2343  last_data_time: 0.2296   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:27:30 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 4619  total_loss: 0.3748  loss_cls: 0.05966  loss_box_reg: 0.1371  loss_mask: 0.1506  loss_rpn_cls: 0.005507  loss_rpn_loc: 0.02448    time: 1.9033  last_time: 1.0696  data_time: 0.2569  last_data_time: 0.2449   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:27:53 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 4639  total_loss: 0.3642  loss_cls: 0.05661  loss_box_reg: 0.1274  loss_mask: 0.1472  loss_rpn_cls: 0.005395  loss_rpn_loc: 0.023    time: 1.8999  last_time: 1.0766  data_time: 0.2519  last_data_time: 0.2494   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:28:15 d2.utils.events]: \u001b[0m eta: 0:06:05  iter: 4659  total_loss: 0.3565  loss_cls: 0.05768  loss_box_reg: 0.1304  loss_mask: 0.1478  loss_rpn_cls: 0.004991  loss_rpn_loc: 0.02327    time: 1.8964  last_time: 1.0459  data_time: 0.2430  last_data_time: 0.2390   lr: 0.0003  max_mem: 11854M\n",
      "\u001b[32m[04/09 19:28:37 d2.utils.events]: \u001b[0m eta: 0:05:44  iter: 4679  total_loss: 0.3808  loss_cls: 0.05771  loss_box_reg: 0.134  loss_mask: 0.1516  loss_rpn_cls: 0.005992  loss_rpn_loc: 0.02446    time: 1.8930  last_time: 1.0495  data_time: 0.2403  last_data_time: 0.2343   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:28:59 d2.utils.events]: \u001b[0m eta: 0:05:22  iter: 4699  total_loss: 0.3591  loss_cls: 0.05632  loss_box_reg: 0.1283  loss_mask: 0.148  loss_rpn_cls: 0.005308  loss_rpn_loc: 0.02443    time: 1.8897  last_time: 1.0641  data_time: 0.2429  last_data_time: 0.2326   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:29:21 d2.utils.events]: \u001b[0m eta: 0:05:01  iter: 4719  total_loss: 0.3664  loss_cls: 0.05875  loss_box_reg: 0.1315  loss_mask: 0.1491  loss_rpn_cls: 0.005261  loss_rpn_loc: 0.02351    time: 1.8863  last_time: 1.0762  data_time: 0.2441  last_data_time: 0.2523   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:29:43 d2.utils.events]: \u001b[0m eta: 0:04:39  iter: 4739  total_loss: 0.3697  loss_cls: 0.05586  loss_box_reg: 0.1307  loss_mask: 0.1478  loss_rpn_cls: 0.005229  loss_rpn_loc: 0.02421    time: 1.8830  last_time: 1.0911  data_time: 0.2447  last_data_time: 0.2379   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:30:05 d2.utils.events]: \u001b[0m eta: 0:04:18  iter: 4759  total_loss: 0.3642  loss_cls: 0.05644  loss_box_reg: 0.1299  loss_mask: 0.1476  loss_rpn_cls: 0.005606  loss_rpn_loc: 0.02289    time: 1.8798  last_time: 1.0872  data_time: 0.2447  last_data_time: 0.2390   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:30:27 d2.utils.events]: \u001b[0m eta: 0:03:56  iter: 4779  total_loss: 0.3572  loss_cls: 0.05507  loss_box_reg: 0.1255  loss_mask: 0.1496  loss_rpn_cls: 0.004648  loss_rpn_loc: 0.02318    time: 1.8766  last_time: 1.0382  data_time: 0.2430  last_data_time: 0.2432   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:30:50 d2.utils.events]: \u001b[0m eta: 0:03:35  iter: 4799  total_loss: 0.3737  loss_cls: 0.05693  loss_box_reg: 0.1338  loss_mask: 0.1491  loss_rpn_cls: 0.00464  loss_rpn_loc: 0.02419    time: 1.8734  last_time: 1.0643  data_time: 0.2394  last_data_time: 0.2408   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:31:12 d2.utils.events]: \u001b[0m eta: 0:03:13  iter: 4819  total_loss: 0.3635  loss_cls: 0.05665  loss_box_reg: 0.1338  loss_mask: 0.1485  loss_rpn_cls: 0.006021  loss_rpn_loc: 0.02383    time: 1.8702  last_time: 1.3287  data_time: 0.2387  last_data_time: 0.2506   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:31:34 d2.utils.events]: \u001b[0m eta: 0:02:52  iter: 4839  total_loss: 0.3585  loss_cls: 0.05659  loss_box_reg: 0.1277  loss_mask: 0.1464  loss_rpn_cls: 0.004766  loss_rpn_loc: 0.02332    time: 1.8670  last_time: 1.0972  data_time: 0.2431  last_data_time: 0.2556   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:31:56 d2.utils.events]: \u001b[0m eta: 0:02:30  iter: 4859  total_loss: 0.3739  loss_cls: 0.05813  loss_box_reg: 0.1349  loss_mask: 0.1459  loss_rpn_cls: 0.005257  loss_rpn_loc: 0.02259    time: 1.8639  last_time: 1.0996  data_time: 0.2524  last_data_time: 0.2898   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:32:19 d2.utils.events]: \u001b[0m eta: 0:02:09  iter: 4879  total_loss: 0.3637  loss_cls: 0.05693  loss_box_reg: 0.1294  loss_mask: 0.1468  loss_rpn_cls: 0.005648  loss_rpn_loc: 0.02387    time: 1.8609  last_time: 1.0668  data_time: 0.2502  last_data_time: 0.2365   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:32:41 d2.utils.events]: \u001b[0m eta: 0:01:47  iter: 4899  total_loss: 0.3614  loss_cls: 0.05424  loss_box_reg: 0.1283  loss_mask: 0.1461  loss_rpn_cls: 0.005334  loss_rpn_loc: 0.02401    time: 1.8579  last_time: 1.0783  data_time: 0.2498  last_data_time: 0.2600   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:33:04 d2.utils.events]: \u001b[0m eta: 0:01:26  iter: 4919  total_loss: 0.3548  loss_cls: 0.05462  loss_box_reg: 0.1245  loss_mask: 0.146  loss_rpn_cls: 0.004546  loss_rpn_loc: 0.02231    time: 1.8549  last_time: 1.0661  data_time: 0.2433  last_data_time: 0.2310   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:33:26 d2.utils.events]: \u001b[0m eta: 0:01:04  iter: 4939  total_loss: 0.3711  loss_cls: 0.05651  loss_box_reg: 0.132  loss_mask: 0.1485  loss_rpn_cls: 0.00466  loss_rpn_loc: 0.02266    time: 1.8519  last_time: 1.0857  data_time: 0.2400  last_data_time: 0.2443   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:33:48 d2.utils.events]: \u001b[0m eta: 0:00:43  iter: 4959  total_loss: 0.3547  loss_cls: 0.0527  loss_box_reg: 0.125  loss_mask: 0.1444  loss_rpn_cls: 0.00472  loss_rpn_loc: 0.02298    time: 1.8488  last_time: 1.0689  data_time: 0.2397  last_data_time: 0.2373   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:34:10 d2.utils.events]: \u001b[0m eta: 0:00:21  iter: 4979  total_loss: 0.3501  loss_cls: 0.05094  loss_box_reg: 0.1233  loss_mask: 0.1471  loss_rpn_cls: 0.004883  loss_rpn_loc: 0.02099    time: 1.8458  last_time: 1.0624  data_time: 0.2412  last_data_time: 0.2370   lr: 0.0003  max_mem: 11987M\n",
      "Saving checkpoint to ./output_detectron2/model_0004999.pth\n",
      "Saving checkpoint to ./output_detectron2/model_final.pth\n",
      "\u001b[32m[04/09 19:34:33 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4999  total_loss: 0.3579  loss_cls: 0.05437  loss_box_reg: 0.1301  loss_mask: 0.1447  loss_rpn_cls: 0.00443  loss_rpn_loc: 0.02292    time: 1.8429  last_time: 1.0758  data_time: 0.2380  last_data_time: 0.2328   lr: 0.0003  max_mem: 11987M\n",
      "\u001b[32m[04/09 19:34:34 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 2:33:30 (1.8429 s / it)\n",
      "\u001b[32m[04/09 19:34:34 d2.engine.hooks]: \u001b[0mTotal training time: 2:33:39 (0:00:08 on hooks)\n"
     ]
    }
   ],
   "source": [
    "trainer.train() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uI3zLAc3yeWq"
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "# Save configuration\n",
    "config_yaml_path = \"./detr2_config.yaml\"\n",
    "with open(config_yaml_path, 'w') as file:\n",
    "    yaml.dump(cfg, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KgcPBalGMB4d"
   },
   "source": [
    "# Inference using the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iyyRL4soMDdE",
    "outputId": "6f4e43aa-e0e8-4fd4-8c0f-b073be34b2a1"
   },
   "outputs": [],
   "source": [
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  \n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  \n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# S0655343836_L\n",
    "\n",
    "img_fname = [train_dataset_dicts[i]['file_name'] for i in range(len(train_dataset_dicts)) \\\n",
    "             if train_dataset_dicts[i]['file_name'].split('/')[-1].startswith('S0412991401_U')]\n",
    "img_fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(val_dataset_dicts), len(train_dataset_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset_dicts[0]['file_name'].split('/')[-1].startswith('S0018141301_M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "2z8JER1KM2Ul",
    "outputId": "61a608df-2ac4-4f3b-a496-d6da1b721d58",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "\n",
    "# for d in val_dataset_dicts[:10]:    \n",
    "im = cv2.imread(img_fname[0])\n",
    "outputs = predictor(im)\n",
    "instances = outputs[\"instances\"]\n",
    "print(d[\"file_name\"].split(\"/\")[-1])\n",
    "if instances.has(\"pred_masks\") and instances.has(\"pred_classes\"):\n",
    "    masks = instances.pred_masks.to(\"cpu\").numpy()  # A binary mask of shape [num_instances, H, W]\n",
    "    classes = instances.pred_classes.to(\"cpu\").numpy()  # An array of class IDs for each instance\n",
    "    scores = instances.scores.to(\"cpu\").numpy()  # An array of scores for each instance\n",
    "    boxes = instances.pred_boxes.tensor.to(\"cpu\").numpy()  # An array of bounding boxes for each instance, shape [num_instances, 4]\n",
    "    plt.imshow(im)\n",
    "    plt.title(f'Detectron2 Masks')\n",
    "    dataset_utils.show_masks(masks, plt.gca()) #, random_color=True)\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "        \n",
    "    # v = Visualizer(im[:, :, ::-1],\n",
    "    #                metadata=val_metadata,\n",
    "    #                scale=0.5,\n",
    "    #                instance_mode=ColorMode.IMAGE_BW   # remove the colors of unsegmented pixels. This option is only available for segmentation models\n",
    "    # )\n",
    "    # out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    # plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PQNSml38OuWV",
    "outputId": "ce72de09-f9d9-4257-dc2a-a60bc149316f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/04 21:31:00 d2.evaluation.coco_evaluation]: \u001b[0mFast COCO eval is not built. Falling back to official COCO eval.\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[04/04 21:31:00 d2.data.datasets.coco]: \u001b[0m\n",
      "Category ids in annotations are not in [1, #categories]! We'll apply a mapping for you.\n",
      "\n",
      "\u001b[32m[04/04 21:31:00 d2.data.datasets.coco]: \u001b[0mLoaded 243 images in COCO format from ./roboflow_datasets/xmm_om_artefacts_512-20-COCO-splits/valid_1/skf_valid_annotations.coco.json\n",
      "\u001b[32m[04/04 21:31:00 d2.data.build]: \u001b[0mDistribution of instances among all 4 categories:\n",
      "\u001b[36m|  category  | #instances   |   category   | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:------------:|:-------------|:----------:|:-------------|\n",
      "| artefacts  | 0            | central-ring | 160          | smoke-ring | 382          |\n",
      "| star-loop  | 444          |              |              |            |              |\n",
      "|   total    | 986          |              |              |            |              |\u001b[0m\n",
      "\u001b[32m[04/04 21:31:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[04/04 21:31:00 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[04/04 21:31:00 d2.data.common]: \u001b[0mSerializing 243 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[04/04 21:31:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.03 MiB\n",
      "\u001b[32m[04/04 21:31:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 243 batches\n",
      "\u001b[32m[04/04 21:31:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/243. Dataloading: 0.0011 s/iter. Inference: 0.0299 s/iter. Eval: 0.0041 s/iter. Total: 0.0351 s/iter. ETA=0:00:08\n",
      "\u001b[32m[04/04 21:31:06 d2.evaluation.evaluator]: \u001b[0mInference done 190/243. Dataloading: 0.0011 s/iter. Inference: 0.0246 s/iter. Eval: 0.0025 s/iter. Total: 0.0283 s/iter. ETA=0:00:01\n",
      "\u001b[32m[04/04 21:31:07 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:06.739937 (0.028319 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/04 21:31:07 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:05 (0.024190 s / iter per device, on 1 devices)\n",
      "\u001b[32m[04/04 21:31:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[04/04 21:31:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_detectron2/coco_instances_results.json\n",
      "\u001b[32m[04/04 21:31:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with official COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=0.21s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.497\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.808\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.539\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.470\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.474\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.378\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.569\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.573\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.556\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.561\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.234\n",
      "\u001b[32m[04/04 21:31:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 49.728 | 80.755 | 53.917 | 46.957 | 47.447 | 20.705 |\n",
      "\u001b[32m[04/04 21:31:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category   | AP     | category     | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-------------|:-------|:-----------|:-------|\n",
      "| artefacts  | nan    | central-ring | 60.864 | smoke-ring | 42.358 |\n",
      "| star-loop  | 45.960 |              |        |            |        |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.01s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *segm*\n",
      "DONE (t=0.46s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.532\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.811\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.608\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.483\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.532\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.623\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.600\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.604\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.587\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.570\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.642\n",
      "\u001b[32m[04/04 21:31:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for segm: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 53.210 | 81.083 | 60.796 | 48.277 | 53.247 | 62.293 |\n",
      "\u001b[32m[04/04 21:31:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category segm AP: \n",
      "| category   | AP     | category     | AP     | category   | AP     |\n",
      "|:-----------|:-------|:-------------|:-------|:-----------|:-------|\n",
      "| artefacts  | nan    | central-ring | 65.042 | smoke-ring | 47.442 |\n",
      "| star-loop  | 47.146 |              |        |            |        |\n",
      "OrderedDict([('bbox', {'AP': 49.72763471856918, 'AP50': 80.7550272501223, 'AP75': 53.91709997011631, 'APs': 46.95670203273239, 'APm': 47.446863713437445, 'APl': 20.70530558694967, 'AP-artefacts': nan, 'AP-central-ring': 60.864224673928604, 'AP-smoke-ring': 42.35836732722216, 'AP-star-loop': 45.96031215455678}), ('segm', {'AP': 53.20984622402658, 'AP50': 81.0829227345466, 'AP75': 60.7961543222345, 'APs': 48.277206015628906, 'APm': 53.24696851891637, 'APl': 62.29305128511044, 'AP-artefacts': nan, 'AP-central-ring': 65.04207000591332, 'AP-smoke-ring': 47.441950979291335, 'AP-star-loop': 47.1455176868751})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(dataset_val, output_dir=\"./output_detectron2\")\n",
    "val_loader = build_detection_test_loader(cfg,dataset_val)\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S0156960101_U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export new annotations to Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "S0112231101_L.png\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Perform prediction on the new image\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mpredictor\u001b[49m(new_im)  \u001b[38;5;66;03m# Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\u001b[39;00m\n\u001b[1;32m     55\u001b[0m instances \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstances\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference time per image:\u001b[39m\u001b[38;5;124m\"\u001b[39m, time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart_time)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "import dataset \n",
    "from dataset import voc_annotate_and_Roboflow_export, dataset_utils\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "export_to_Roboflow = True\n",
    "\n",
    "if export_to_Roboflow:\n",
    "    # Initialize Roboflow client\n",
    "    rf = Roboflow(api_key=\"EBeK30tpU3HW2VGGl0xa\")\n",
    "    upload_project = rf.workspace(\"iuliaelisa\").project(\"xmm_om_artefacts_512\") # error if the project doesn't exist\n",
    "    \n",
    "def export_image_det_to_Roboflow(input_dir, filename, masks, class_label, boxes):\n",
    "        \n",
    "        objects = []\n",
    "        for i in range(len(masks)):\n",
    "            mask_np = masks[i] # [H, W]\n",
    "            polygon = voc_annotate_and_Roboflow_export.binary_image_to_polygon(mask_np)\n",
    "            bbox = boxes[i]\n",
    "            objects.append({\n",
    "                'name': train_metadata.thing_classes[class_label[i]],\n",
    "                'bbox': bbox,\n",
    "                'segmentations': polygon[0]\n",
    "            })\n",
    "        if len(objects)>0:\n",
    "            voc_annotate_and_Roboflow_export.create_annotation_SAM(\n",
    "                filename=filename, \n",
    "                width=512, \n",
    "                height=512, \n",
    "                depth=3, \n",
    "                objects=objects, \n",
    "                offset= 1.3) # generating xml file for VOC format\n",
    "            annotation_filename = filename.replace(\".png\", \".xml\")\n",
    "            upload_project.upload(input_dir+filename, annotation_filename, overwrite=True)\n",
    "            os.remove(annotation_filename)\n",
    "        else:\n",
    "            upload_project.upload(input_dir+filename, overwrite=True)\n",
    "    \n",
    "# Directory path to the input images folder\n",
    "input_images_directory = \"../XMM_OM_dataset/zscaled_512_stretched/\"\n",
    "\n",
    "# Output directory where the segmented images will be saved\n",
    "output_directory = \".\"  \n",
    "import time\n",
    "for image_filename in os.listdir(input_images_directory)[2035:2045]:\n",
    "    if not image_filename.endswith('.json'):\n",
    "        print(image_filename)\n",
    "        image_path = os.path.join(input_images_directory, image_filename)\n",
    "        new_im = cv2.imread(image_path)\n",
    "        start_time = time.time()\n",
    "        # Perform prediction on the new image\n",
    "        outputs = predictor(new_im)  # Format is documented at https://detectron2.readthedocs.io/tutorials/models.html#model-output-format\n",
    "        instances = outputs[\"instances\"]\n",
    "        print(\"Inference time per image:\", time.time()-start_time)\n",
    "\n",
    "        if instances.has(\"pred_masks\") and instances.has(\"pred_classes\"):\n",
    "            masks = instances.pred_masks.to(\"cpu\").numpy()  # A binary mask of shape [num_instances, H, W]\n",
    "            classes = instances.pred_classes.to(\"cpu\").numpy()  # An array of class IDs for each instance\n",
    "            scores = instances.scores.to(\"cpu\").numpy()  # An array of scores for each instance\n",
    "            boxes = instances.pred_boxes.tensor.to(\"cpu\").numpy()  # An array of bounding boxes for each instance, shape [num_instances, 4]\n",
    "            # if export_to_Roboflow:\n",
    "            #     export_image_det_to_Roboflow(input_images_directory, image_filename, masks, classes, boxes)\n",
    "            plt.imshow(new_im)\n",
    "            plt.title('Detectron2 Masks')\n",
    "            dataset_utils.show_masks(masks, plt.gca()) #, random_color=True)\n",
    "            # plt.savefig('./plots/detr2_masks.png')\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "\n",
    "print(\"Segmentation of all images completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPhrr2e71uZZXW4xJXEF5QT",
   "gpuType": "T4",
   "include_colab_link": true,
   "mount_file_id": "16uxXOT0U8KYhI02okV_sWhjgOy6Mbktv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "env_py311",
   "language": "python",
   "name": "env_py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0010cea7536444888d4b240b5a2a48b8": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "06e1876af40c476988d0e37378b3c769": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "08c38db47ac04e87bf53b38d069c4f8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_0010cea7536444888d4b240b5a2a48b8",
       "max": 1,
       "style": "IPY_MODEL_1447d938d8f943008d4a830724aacd67"
      }
     },
     "1447d938d8f943008d4a830724aacd67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "2fa2f4a508c441cb9d6ce73514842cdc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_8f25ae3963aa4d4096e6dc54ac62dd08",
       "style": "IPY_MODEL_4420d8b395c14b1fb6fff772dbd4345d"
      }
     },
     "4420d8b395c14b1fb6fff772dbd4345d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "73bdbc2a840e49fc8bd566824f6ee314": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "78db4e3b639549f3b1c959e527720af8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelStyleModel",
      "state": {
       "description_width": "",
       "font_family": null,
       "font_size": null,
       "font_style": null,
       "font_variant": null,
       "font_weight": null,
       "text_color": null,
       "text_decoration": null
      }
     },
     "8f25ae3963aa4d4096e6dc54ac62dd08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ab14347832294345b75dfcc8e6d5dded": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b48e4dfbe5d4408b86c54e427e9b29cf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_dc96a4bed40a470dbb2227ff4f8230fb",
        "IPY_MODEL_f347f476f94049bfb3ee46a83500e3f1"
       ],
       "layout": "IPY_MODEL_73bdbc2a840e49fc8bd566824f6ee314"
      }
     },
     "bacf8cbf58e64a74a17408a39eccbef5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bc0f7656ddba4cf099932c8dead4e93f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "VBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_2fa2f4a508c441cb9d6ce73514842cdc",
        "IPY_MODEL_08c38db47ac04e87bf53b38d069c4f8e"
       ],
       "layout": "IPY_MODEL_bacf8cbf58e64a74a17408a39eccbef5"
      }
     },
     "dc96a4bed40a470dbb2227ff4f8230fb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_fe4c5f82da0f4132b1203263d44daf27",
       "style": "IPY_MODEL_78db4e3b639549f3b1c959e527720af8"
      }
     },
     "f347f476f94049bfb3ee46a83500e3f1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_ab14347832294345b75dfcc8e6d5dded",
       "max": 1,
       "style": "IPY_MODEL_06e1876af40c476988d0e37378b3c769"
      }
     },
     "fe4c5f82da0f4132b1203263d44daf27": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
