{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M14ZHzGMCGO"
   },
   "source": [
    "# OM data prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-M14ZHzGMCGO"
   },
   "source": [
    "## About OM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRz_h0qBJ0Sb"
   },
   "source": [
    " This code uses the processed images from XMM-Newton's **Opical Monitor**. The images are **diffraction-limited** and each of the 5 exposures per filter are sub-windows covering 92% of the 17'x17' FOV (*2048x2048* pixels). The windows are stacked (2048x2048) and rebinned to **256x256** for computational efficiency. \n",
    " \n",
    " Information about the configuration of the OM (e.g.: sub-windows stacking) can be found here: https://www.mssl.ucl.ac.uk/www_xmm/ukos/onlines/uhb/XMM_UHB/node62.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShyIEYFM5Tjb"
   },
   "source": [
    "## Input and mount data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "!pip install astropy\n",
    "import matplotlib.pyplot as plt\n",
    "# !pip install roboflow \n",
    "from roboflow import Roboflow\n",
    "import csv\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from scipy.interpolate import interp1d\n",
    "from astropy.visualization import ZScaleInterval, ImageNormalize\n",
    "\n",
    "# this is needed to reload changes from imported modules, without the need to restart the kernel\n",
    "from importlib import reload\n",
    "import astronomy_utils\n",
    "reload(astronomy_utils)\n",
    "from astronomy_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U6ZFCVRk1Tu7"
   },
   "outputs": [],
   "source": [
    "OM_dir =  \"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/\"\n",
    "OM_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Roboflow data mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# rf = Roboflow(api_key=\"GGtO5x2eJ77Wa0rLpQSt\")\n",
    "\n",
    "# # print(rf.workspace())\n",
    "\n",
    "# project = rf.workspace(\"orij\").project(\"om_sky_images\")\n",
    "\n",
    "# for file_ in os.listdir(OM_dir):\n",
    "#     if \"png\" in file_:\n",
    "#         project.upload(\"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/\"+file_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zooniverse data mounting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_, delete_ = False, False\n",
    "\n",
    "# dir_ = \"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/\"\n",
    "# segmented_dir_name = \"segmented_SAM/\"\n",
    "# raw_dir_name = \"scaled_raw/\"\n",
    "\n",
    "# segmented_files = [file_img_ for file_img_ in os.listdir(dir_+segmented_dir_name) \\\n",
    "#                       if os.path.isfile(os.path.join(dir_+segmented_dir_name, file_img_)) and \"png\" in file_img_.split(\".\")[-1]]\n",
    "\n",
    "# if write_ : \n",
    "#     with open('/workspace/raid/OM_DeepLearning/manifest.csv', 'w', newline='') as csvfile:\n",
    "#         csvwriter = csv.writer(csvfile)\n",
    "#         csvwriter.writerow([ '#origin1',  '#origin2', 'metadata'])\n",
    "       \n",
    "#         for img_ in segmented_files:\n",
    "#             output_segm = dir_+segmented_dir_name+f'temp_segm{img_.replace(\"_segmented.png\", \"\")}.png'\n",
    "#             output_raw = dir_+raw_dir_name+f'temp_raw{img_.replace(\"_segmented.png\", \"\")}.png'\n",
    "            \n",
    "#             bigger_image_segm = Image.open(dir_+segmented_dir_name+img_).resize((512, 512)) #display a bigger image in Zooniverse\n",
    "#             bigger_image_segm.save(output_segm)\n",
    "#             bigger_image_scaled_raw = Image.open(dir_+raw_dir_name+img_.replace(\"_segmented\", \"\")).resize((512, 512)) #display a bigger image in Zooniverse\n",
    "#             bigger_image_scaled_raw.save(output_raw)\n",
    "            \n",
    "#             csvwriter.writerow([output_raw, output_segm, img_.replace(\"_segmented.png\", \"\")])\n",
    "    \n",
    "# # delete temporary files after uploading them to Zooniverse Subject set.\n",
    "# if delete_:\n",
    "#     try:\n",
    "#         for img_ in segmented_files:\n",
    "#              if \"temp\" in img_:\n",
    "#                  os.remove(dir_+segmented_dir_name+img_)\n",
    "#                  os.remove(dir_+raw_dir_name+img_.replace(\"segm\", \"raw\"))\n",
    "#     except Exception as e:\n",
    "#         print(\"Exception for deleting temporary files: \", e)\n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_ = \"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/\"\n",
    "\n",
    "# img = Image.open(dir_+segmented_dir_name+\"S0300880101_U_segmented.png\")\n",
    "# print(np.array(img).shape)\n",
    "# img.show()\n",
    "\n",
    "# img = Image.open(dir_+raw_dir_name+\"S0300880101_U.png\")\n",
    "# print(np.array(img).shape)\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xpTByCJXs-1u"
   },
   "source": [
    "# Optical Monitor images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filling missing (-1) pixels with distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill Poisson Localised\n",
    "\n",
    "> We fill out bad pixels and detector gaps by the simulated Poisson\n",
    "counts with the expected value of a local mean, calculated as the\n",
    "mean of pixel values within a box of 15 Ã— 15 pixels around a given\n",
    "position. In case the fraction of masked pixels within that box is more\n",
    "than 30%, the wider box is taken. This procedure is repeated until all\n",
    "masked pixels are filled out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create clusters of points, \n",
    "# these clusters are themselves distributed according to a Poisson process,\n",
    "# within each cluster, points are normally distributed\n",
    "\n",
    "def thomas(mu, sigma, nu, size=1):\n",
    "    \"\"\"\n",
    "    Generate Thomas distributed random numbers.\n",
    "    mu: mean of the clusters\n",
    "    sigma: standard deviation within clusters\n",
    "    nu: mean number of points per cluster\n",
    "    size: number of random numbers to generate\n",
    "    \"\"\"\n",
    "    num_clusters = np.random.poisson(nu, size)\n",
    "    \n",
    "    # Generate Thomas distributed numbers\n",
    "    result = []\n",
    "    for clusters in num_clusters:\n",
    "        for _ in range(clusters):\n",
    "            result.append(np.random.normal(mu, sigma))\n",
    "    \n",
    "    return np.array(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking image histograms for gaussian threshold_sigma\n",
    "\n",
    "def image_histogram(data_array):\n",
    "    \n",
    "    # Calculate the histogram\n",
    "    hist, bins = np.histogram(data_array, bins=50)\n",
    "    \n",
    "    # Plot the histogram\n",
    "    plt.hist(data_array, bins=20, color='blue', alpha=0.7)\n",
    "    plt.title('Histogram')\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(value, old_min, old_max, new_min, new_max):\n",
    "    return (value - old_min) / (old_max - old_min) * (new_max - new_min) + new_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import fftconvolve\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def fill_localised(input_array, distribution = 'poisson', size_input=2):\n",
    "    \"\"\"\n",
    "    Fills all masked elements of an array with poisson/gaussian signal with local expected value.\n",
    "    \"\"\"\n",
    "    array = np.ma.masked_less(input_array, 0)\n",
    "   \n",
    "    if not (isinstance(array, np.ma.MaskedArray)):\n",
    "        print('No mask found')\n",
    "        return input_array\n",
    "    size = size_input\n",
    "    output = array.data.copy()\n",
    "    mask = array.mask.copy()\n",
    "    mask_full = np.ones(mask.shape)\n",
    "    \n",
    "    # print(mask.sum())\n",
    "    while mask.sum() > 1:\n",
    "        kernel = np.ones((size, size))/size**2 #creates a kernel of ones with shape (size, size) normalized by size**2.\n",
    "        coeff_full = fftconvolve(mask_full, kernel, mode='same')\n",
    "        coeff = fftconvolve(np.logical_not(mask), kernel, mode='same') / coeff_full\n",
    "        mean = fftconvolve(output, kernel, mode='same')\n",
    "        \n",
    "        # compute stdev\n",
    "        diff = output - mean\n",
    "        sq_diff = fftconvolve(diff**2, kernel, mode='same')\n",
    "        sq_diff = np.clip(sq_diff, 0, None)\n",
    "        std_dev = np.sqrt(sq_diff)\n",
    "        norm_ = data_norm(mean[mean>=0])\n",
    "        # plt.figure(figsize=(3,3)) \n",
    "        # plt.imshow(mean, cmap='gray', norm=norm_)\n",
    "        # plt.axis('off')\n",
    "        # plt.tight_layout(pad=0, w_pad=0, h_pad=0)\n",
    "        # plt.show()\n",
    "        idx = np.where(np.logical_and(mask, coeff > 0.5))\n",
    "        lambda_ = np.abs(mean[idx]/coeff[idx])\n",
    "        std = np.abs(std_dev[idx]/coeff[idx])\n",
    "        \n",
    "        if distribution == 'poisson':\n",
    "            output[idx] = np.abs(np.random.poisson(lambda_))\n",
    "        if distribution == 'gaussian':\n",
    "            output[idx] = np.abs(np.random.normal(lambda_, std))/8\n",
    "        # print(f'Lambda: {output[idx]}')\n",
    "        # print(f'Output --- Min: {min(output[idx])}, Max: {max(output[idx])}, Mean: {np.mean(output[idx])}, Var: {np.var(output[idx])}')\n",
    "        output[idx] = rescale(output[idx], 0, 1, np.min(output[idx]), np.max(output[idx]))\n",
    "        if distribution == 'thomas':\n",
    "            mu = np.mean(mean)  # Compute mu from mean array\n",
    "            # print(len(output[idx]))\n",
    "            output[idx] = thomas(mu, 1, 1, size=3183)\n",
    "        mask[idx] = False\n",
    "        size += size_input\n",
    "        size += (1 - size % 2)\n",
    "    norm_ = data_norm(output)\n",
    "    \n",
    "    plt.figure() \n",
    "    plt.imshow(output, cmap='gray', norm=norm_)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout(pad=0, w_pad=0, h_pad=0)\n",
    "    plt.show()\n",
    "    return output\n",
    "IMAGE_NAME = \"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/S0103060201_S.fits\"\n",
    "IMAGE_PATH = os.path.join(OM_dir,IMAGE_NAME)\n",
    "original_image = fits.open(IMAGE_PATH)[0].data\n",
    "output1 = fill_localised(original_image, 'gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMAGE_NAME = \"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/S0844260101_U.fits\"\n",
    "IMAGE_PATH = os.path.join(OM_dir,IMAGE_NAME)\n",
    "original_image2 = fits.open(IMAGE_PATH)[0].data\n",
    "original_image2 = original_image2\n",
    "output2 = fill_localised(original_image2, 'gaussian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code highlights the negative pixels in an image in black\n",
    "import matplotlib.image as mpimg\n",
    "from PIL import Image\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "# IMAGE_NAME = \"S0655570201_L.fits\"\n",
    "# IMAGE_PATH = os.path.join(OM_dir,IMAGE_NAME)\n",
    "# original_image = fits.open(IMAGE_PATH)[0].data\n",
    "\n",
    "# image_data = original_image.copy()\n",
    "\n",
    "# image_data[image_data == -1] = np.nan\n",
    "# image_data[image_data >=0 ] = 1\n",
    "# fig, ax = plt.subplots(figsize=(60, 40))\n",
    "\n",
    "# cax = ax.imshow(image_data, cmap='gray', vmin=0, vmax=1)\n",
    "\n",
    "# cmap = plt.get_cmap('gray')\n",
    "# cmap.set_bad(color='black', alpha=1.0)\n",
    "# cax.cmap.set_bad(color='black', alpha=1.0)\n",
    "\n",
    "# cbar = fig.colorbar(cax)\n",
    "\n",
    "# # Display the plot\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_sigma(image_array, sigma_):\n",
    "\n",
    "    print(\"Computing sigma thresholding only for on-zero pixel image array:\")\n",
    "    mean_value = np.mean(image_array)\n",
    "    std_dev = np.std(image_array)\n",
    "    threshold = mean_value + sigma_ * std_dev\n",
    "    print(\"\\u03BC =\", mean_value, \"\\u03C3 =\", std_dev, f\", threshold: \\u03BC + {sigma_} * \\u03C3:\", threshold)\n",
    "    \n",
    "    # Extract the values within \"sigma_\" standard deviation\n",
    "    values_within_3_sigma = []\n",
    "    for i in range(len(image_array)):\n",
    "            if(image_array[i] < threshold):\n",
    "                values_within_3_sigma.append(image_array[i])\n",
    "\n",
    "    return values_within_3_sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# threshold_sigma(original_image[original_image>=0], sigma_=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_histogram(np.ndarray.flatten(original_image)) # should consider cutting the histogram due to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_missing_data_with_distribution(fits_path, distribution='gaussian', seed=2):\n",
    "    '''\n",
    "    This selectively replace certain values in an array with random values from a Gaussian distribution for the negative pixels.\n",
    "    '''\n",
    "    # image_data = np.array(Image.open(image_path).convert(\"L\"))  # Convert to grayscale\n",
    "    hdul = fits.open(fits_path)\n",
    "\n",
    "    #apparently, I need to flip the matrix horizontally, otherwise the output is mirrored.\n",
    "    fits_data = hdul[0].data.copy() #* 1480\n",
    "\n",
    "    fits_data = np.flipud(fits_data)\n",
    "    hdul.close()\n",
    "\n",
    "    # take only values at a sigma value (close to background) and non-zero\n",
    "    valid_data = threshold_sigma(fits_data[fits_data>=0], sigma_ = 1)\n",
    "    print(\"-----------------------------------\")\n",
    "    \n",
    "    print(\"# negative pixels: \", np.count_nonzero(fits_data[fits_data==-1]))\n",
    "    \n",
    "    print(\"-----------------------------------\")\n",
    "    print(\"Fill missing data with distribution: \")\n",
    "    if distribution == 'gaussian':\n",
    "        mu = np.median(valid_data)\n",
    "        sigma = np.std(valid_data)    # I took here a fraction, because otherwise it doesn't look natural\n",
    "        generator = np.random.default_rng(0)\n",
    "        filled_data = np.matrix(fits_data)\n",
    "        num_rows, num_cols = filled_data.shape\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                if(fits_data[i,j] < 0):\n",
    "                    filled_data[i,j] = np.abs(generator.normal(mu, sigma))/1.05\n",
    "                   \n",
    "        return np.array(filled_data), mu, sigma\n",
    "\n",
    "    elif distribution == 'poisson':\n",
    "        lambda_ = np.mean(valid_data)\n",
    "        print(\"Lambda:\", lambda_)\n",
    "        generator = np.random.default_rng(0)\n",
    "        filled_data = np.matrix(fits_data)\n",
    "        num_rows, num_cols = filled_data.shape\n",
    "        for i in range(num_rows):\n",
    "            for j in range(num_cols):\n",
    "                if(fits_data[i,j] < 0):\n",
    "                    filled_data[i,j] = generator.poisson(lambda_)\n",
    "                   \n",
    "        return np.array(filled_data), lambda_\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid distribution type\")\n",
    "    return None\n",
    "\n",
    "OM_dir= '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/'\n",
    "imgs = ['S0802200201_M.fits', 'S0673730101_U.fits', 'S0673350201_U.fits', 'S0304201401_U.fits', 'S0100240801_U.fits', 'S0302884001_M.fits']\n",
    "for img_path in imgs:\n",
    "    if img_path.endswith('.fits'):\n",
    "        IMAGE_PATH = os.path.join(OM_dir,img_path)\n",
    "        original_image = fits.open(IMAGE_PATH)[0].data.copy()\n",
    "        original_image = np.flipud(original_image) # here flip the fits data\n",
    "    \n",
    "        print(original_image.shape)\n",
    "    \n",
    "        distr = 'gaussian'\n",
    "    \n",
    "        if distr == 'poisson':\n",
    "            modified_image, lambda_ = fill_missing_data_with_distribution(IMAGE_PATH, distribution=distr)\n",
    "            lambda_ = '%.3f'%lambda_\n",
    "        if distr == 'gaussian':\n",
    "            modified_image, mu, sigma = fill_missing_data_with_distribution(IMAGE_PATH, distribution=distr)\n",
    "            mu = '%.3f'%mu\n",
    "            sigma = '%.3f'%sigma\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(20, 6))  \n",
    "    \n",
    "        # normalize image with ZScale considering only non-negative pixels\n",
    "        norm_original = data_norm(original_image[original_image>=0])\n",
    "        norm_modified = data_norm(modified_image[original_image>=0])\n",
    "    \n",
    "        axs[0].imshow(original_image, cmap=\"gray\", norm=norm_original)\n",
    "        axs[1].imshow(modified_image, cmap=\"gray\", norm=norm_modified)\n",
    "    \n",
    "        axs[0].set_title(f'Zscaled image')\n",
    "    \n",
    "        output_image = f'{IMAGE_NAME.replace(\".fits\", \"\")}'\n",
    "        if distr == 'poisson':\n",
    "            axs[1].set_title(f'Filled image with Poisson distr., Î»={lambda_}\\n {IMAGE_PATH.split(\"/\")[-1]}')\n",
    "            output_image = output_image+\"_poisson_plot.png\"\n",
    "        else:\n",
    "            axs[1].set_title(f'Filled image with Gaussian distr., \\n xÍ‚={mu}, \\u03C3={sigma}\\n {IMAGE_PATH.split(\"/\")[-1]}')\n",
    "            output_image = output_image+\"_gaussian_plot.png\"\n",
    "        print(np.min(modified_image), np.max(modified_image))\n",
    "\n",
    "        # Apply zscale normalization only on non-negative data\n",
    "        norm = data_norm(modified_image[modified_image>0])\n",
    "        normalized_data = norm(modified_image)\n",
    "        \n",
    "        # Convert masked array to normal NumPy array\n",
    "        normalized_data = normalized_data.filled(fill_value=-1)\n",
    "\n",
    "        # clip to 255, because some pixels are very big\n",
    "        scaled_data = np.clip((normalized_data * 255), 0, 255).astype(np.uint8)\n",
    "        # scaled_data = 255 - scaled_data\n",
    "        \n",
    "        cv2.imwrite('./gaussian_distrib/'+img_path.replace('.fits', '.png'), 255-scaled_data)\n",
    "        plt.show()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zscale and save images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# filename_ = OM_dir+\"S0554500201_L.fits\"\n",
    "# img_ = zscale_image(filename_.replace(\"png\", \"fits\"), '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/', with_image_stretch=True)\n",
    "\n",
    "if 1==1:\n",
    "    dir_files = [f for f in os.listdir(OM_dir) if os.path.isfile(os.path.join(OM_dir, f))]\n",
    "    for file_ in dir_files:\n",
    "        try:\n",
    "            if file_.endswith(\"fits\"):\n",
    "                zscale_image(OM_dir+file_, OM_dir, with_image_stretch=False)\n",
    "        except Exception as e:\n",
    "            print(file_, e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OM_dir = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLAHE algorithm\n",
    "\n",
    "\n",
    "```\n",
    "Contrast Limited Adaptive Histogram Equalization\n",
    "```\n",
    "\n",
    "\n",
    "(https://www.mathworks.com/help/visionhdl/ug/contrast-adaptive-histogram-equalization.html)\n",
    "\n",
    "\n",
    "When Clip Limit (CL) is increased, the image becomes brighter because the input image has a very low intensity and a larger CL makes its histogram flatter. As the Block Size (BS) increases, the dynamic range expands, and the image contrast increases. The two parameters determined at the point of maximum entropy curvature produce subjectively good image quality when using image entropy. (https://www.analyticsvidhya.com/blog/2022/08/image-contrast-enhancement-using-clahe/)\n",
    "\n",
    "If using a binary threshold, OTSU is the best way to find the best value. If necessary, K-means can be used.\n",
    "\n",
    "\n",
    "There are two parameters to remember when using CLAHE:\n",
    "\n",
    "clipLimit â€“ This parameter controls the contrast limiting threshold. The default setting is 40.\n",
    "\n",
    "tileGridSize â€“ Determines the number of tiles in each row and column. This is set to 88 by default. It is applied while the image is divided into tiles for CLAHE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "in_dir = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw_512/'\n",
    "file_name = 'S0202730101_B.png'\n",
    "\n",
    "if True:\n",
    "# for file_name in os.listdir(in_dir):\n",
    "    if file_name.endswith('png') and 'clahe' not in file_name:\n",
    "        final_img = clahe_algo_image(in_dir+file_name, clipLimit=3.0)\n",
    "        cv2.imwrite(f'{in_dir}clahe_{file_name}', final_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_PATH = '/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/S0655570201_L.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Gaussian over image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "image_2d = plt.imread(\"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/S0111160201_V.png\")\n",
    "x = np.arange(image_2d.shape[0])\n",
    "y = np.arange(image_2d.shape[1])\n",
    "# alpha = np.ones(x.shape)\n",
    "\n",
    "x, y = np.meshgrid(x, y)\n",
    "# alpha = 1\n",
    "\n",
    "# z = image_2d[:, :, 0] * alpha + image_2d[:, :, 1] * (1 - alpha)\n",
    "z = image_2d\n",
    "\n",
    "# Create a single subplot\n",
    "fig = plt.figure(figsize=(13, 6))\n",
    "\n",
    "# Add the first subplot\n",
    "ax1 = fig.add_subplot(121, projection='3d')\n",
    "ax1.plot_surface(y, x, z, cmap='viridis')\n",
    "\n",
    "# Add the second subplot\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.imshow(image_2d, cmap='gray')\n",
    "\n",
    "ax1.set_xlabel('y')\n",
    "ax1.set_ylabel('x')\n",
    "ax1.set_zlabel('z')\n",
    "ax1.set_title('3D image (z=pixels intensity)')\n",
    "\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('y')\n",
    "ax2.set_title('2D original image')\n",
    "plt.subplots_adjust(wspace=0.1)\n",
    "plt.show()\n",
    "# plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet methods\n",
    "\n",
    "Paper: https://arxiv.org/abs/2310.10516\n",
    "\n",
    "source code: http://heagit.cosmos.ru/nustar/nuwavdet\n",
    "\n",
    "\n",
    "This code works on python > 3.10. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 --version\n",
    "\n",
    "# It might show an older version, but still python > 3.10 is active  for the code\n",
    "os.readlink('/proc/%d/exe' % os.getppid())\n",
    "from nuwavdet import nuwavdet as nw\n",
    "print(nw.binary_array(2))\n",
    "\n",
    "import pywt\n",
    "import pywt.data\n",
    "\n",
    "# Load image\n",
    "original = plt.imread(\"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/S0111160201_V.png\")\n",
    "print(type(original))\n",
    "\n",
    "# Wavelet transform of image, and plot approximation and details\n",
    "titles = ['Approximation', ' Horizontal detail',\n",
    "          'Vertical detail', 'Diagonal detail']\n",
    "coeffs2 = pywt.dwt2(original, 'bior1.3')\n",
    "LL, (LH, HL, HH) = coeffs2\n",
    "fig = plt.figure(figsize=(10, 20))\n",
    "for i, a in enumerate([LL, LH, HL, HH]):\n",
    "    ax = fig.add_subplot(1, 4, i + 1)\n",
    "    ax.imshow(a, interpolation=\"nearest\", cmap=plt.cm.gray)\n",
    "    ax.set_title(titles[i], fontsize=10)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# !pip install scipy==1.9.1 --upgrade\n",
    "def atrous(level=0, max_size = 1001):\n",
    "    \"\"\"\n",
    "    Returns a trous kernel with the size 2**level and corresponding shape.\n",
    "    \"\"\"\n",
    "    base = 1/256*np.array([\n",
    "        [1,  4,  6,  4, 1],\n",
    "        [4, 16, 24, 16, 4],\n",
    "        [6, 24, 36, 24, 6],\n",
    "        [4, 16, 24, 16, 4],\n",
    "        [1,  4,  6,  4, 1],\n",
    "    ])\n",
    "    size = 2**level * (base.shape[0]-1)+1\n",
    "    output = np.zeros((size, size))\n",
    "    output[::2**level, ::2**level] = base\n",
    "    if output.shape[0] > max_size:\n",
    "        return output[(size-1)//2-(max_size-1)//2:(size-1)//2+(max_size-1)//2+1,\n",
    "                      (size-1)//2-(max_size-1)//2:(size-1)//2+(max_size-1)//2+1]\n",
    "    return output\n",
    "def atrous_sig(level: int = 0) -> float:\n",
    "    # sig_values = [0.8908, 0.20066, 0.08551, 0.04122, 0.02042]\n",
    "    sig_values = [0.8725, 0.1893, 0.0946, 0.0473, 0.0237]\n",
    "    if level < 5:\n",
    "        return sig_values[level]\n",
    "    else:\n",
    "        return sig_values[4]/2**(level-4)\n",
    "def gauss(level: int = 0, max_size: int = 1000) -> list[list[float]]:\n",
    "    \"\"\"\n",
    "    Returns gaussian kernel with sigma = 2**level\n",
    "    \"\"\"\n",
    "    size = min(5*2**(level+1)+1, max_size)\n",
    "    sigma = 2**(level)\n",
    "    A = 1/(2*np.pi*sigma**2)**0.5\n",
    "    x = A*np.exp((-(np.arange(size)-(size-1)//2)**2)/(2*sigma**2))\n",
    "    out = np.multiply.outer(x, x)\n",
    "    return out\n",
    "\n",
    "from scipy.signal import fftconvolve\n",
    "\n",
    "def adjecent(array):\n",
    "    \"\"\"\n",
    "    Returns two lists of indices of cells adjecent or diagonal to non-zero cells of given array\n",
    "    \"\"\"\n",
    "    grid = np.array([\n",
    "        [1, 1, 1],\n",
    "        [1, 0, 1],\n",
    "        [1, 1, 1]\n",
    "    ])\n",
    "    output = fftconvolve(array, grid, mode='same') >= 0.5\n",
    "    try:\n",
    "        output = np.logical_and(np.logical_and(output, np.logical_not(array)),\n",
    "                                np.logical_not(array.mask))\n",
    "    except AttributeError:\n",
    "        output = np.logical_and(output, np.logical_not(array))\n",
    "    return output\n",
    "\n",
    "def fill_poisson(array_input, size_input=15):\n",
    "    from numpy import ma\n",
    "    \"\"\"\n",
    "    Fills all masked elements of an array with poisson signal with local expected value.\n",
    "    \"\"\"\n",
    "    array = ma.masked_array(array_input)\n",
    "    if not (isinstance(array, np.ma.MaskedArray)):\n",
    "        print('No mask found')\n",
    "        return array\n",
    "    size = size_input\n",
    "    output = array.data.copy()\n",
    "    mask = array.mask.copy()\n",
    "\n",
    "    print(mask)\n",
    "    mask_full = np.ones(mask.shape)\n",
    "    while mask.sum() > 1:\n",
    "        kernel = np.ones((size, size))/size**2\n",
    "        coeff_full = fftconvolve(mask_full, kernel, mode='same')\n",
    "        coeff = fftconvolve(np.logical_not(mask), kernel, mode='same') / coeff_full\n",
    "        mean = fftconvolve(output, kernel, mode='same')\n",
    "        idx = np.where(np.logical_and(mask, coeff > 0.7))\n",
    "        output[idx] = np.random.poisson(np.abs(mean[idx]/coeff[idx]))\n",
    "        mask[idx] = False\n",
    "        size += size_input\n",
    "        size += (1 - size % 2)\n",
    "    return output\n",
    "poisson_ = fill_poisson(original_image)\n",
    "\n",
    "# norm_poisson = data_norm(poisson_[poisson_>=0])\n",
    "# plt.imshow(poisson_, cmap=\"gray\", norm=norm_poisson)\n",
    "# plt.axis('off')\n",
    "# plt.savefig('gaussian_.png')\n",
    "# plt.show()\n",
    "\n",
    "# !pip install opencv-python-headless\n",
    "import numpy as np\n",
    "import cv2\n",
    "from scipy.signal import convolve\n",
    "img = cv2.imread(\"/workspace/raid/OM_DeepLearning/XMM_OM_dataset/scaled_raw/S0111160201_V.png\")\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Define the wavelet filter\n",
    "wavelet_filter = np.array([[1, 4, 6, 4, 1],\n",
    "                           [4, 6, 24, 16, 4],\n",
    "                           [6, 24, 36, 24, 6],\n",
    "                           [4, 6, 24, 16, 4],\n",
    "                           [1, 4, 6, 4, 1]]) / 256\n",
    "\n",
    "# Compute the wavelet coefficients at each scale\n",
    "wavelet_coefficients = []\n",
    "for i in range(3):\n",
    "    wavelet_coefficients.append(convolve(gray, wavelet_filter, mode='same'))\n",
    "\n",
    "# Upsample the wavelet coefficients at each scale\n",
    "upsampled_wavelet_coefficients = []\n",
    "for i in range(3):\n",
    "    upsampled_wavelet_coefficients.append(cv2.resize(wavelet_coefficients[i], (img.shape[1], img.shape[0])))\n",
    "\n",
    "# Reconstruct the image at each scale\n",
    "reconstructed_images = []\n",
    "for i in range(3):\n",
    "    reconstructed_image = gray + upsampled_wavelet_coefficients[i]\n",
    "    reconstructed_images.append(reconstructed_image)\n",
    "final_image1 = np.zeros_like(img)\n",
    "final_image2 = np.zeros_like(img)\n",
    "final_image3 = np.zeros_like(img)\n",
    "\n",
    "final_image = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "\n",
    "for x in range(final_image.shape[0]):\n",
    "    for y in range(final_image.shape[1]):\n",
    "        for z in range(final_image.shape[2]):\n",
    "            final_image1[x][y][z] = final_image1[x][y][z] + reconstructed_images[0][x][y] # Idk if this is really OK\n",
    "            final_image2[x][y][z] = final_image2[x][y][z] + reconstructed_images[1][x][y] # Idk if this is really OK\n",
    "            final_image3[x][y][z] = final_image3[x][y][z] + reconstructed_images[2][x][y] # Idk if this is really OK\n",
    "                \n",
    "cv2.imwrite(\"/workspace/raid/OM_DeepLearning/XMM_OM_code/atrous_wavelet_dec1.png\", final_image1)\n",
    "cv2.imwrite(\"/workspace/raid/OM_DeepLearning/XMM_OM_code/atrous_wavelet_dec2.png\", final_image2)\n",
    "cv2.imwrite(\"/workspace/raid/OM_DeepLearning/XMM_OM_code/atrous_wavelet_dec3.png\", final_image3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find which files are from the same observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = OM_dir\n",
    "file_groups = {}\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path) and filename.endswith(\"png\"):\n",
    "        key = filename[1:11] # afaik, an OM obs id has the same first 11 characters for any filter\n",
    "        if key in file_groups:\n",
    "            file_groups[key].append(file_path)\n",
    "        else:\n",
    "            file_groups[key] = [file_path]\n",
    "\n",
    "for key, files in file_groups.items():\n",
    "    if len(files) >=2:\n",
    "        print(f\"Group '{key}':\")\n",
    "        for file in files:\n",
    "            print(f\"  {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py311",
   "language": "python",
   "name": "env_py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
